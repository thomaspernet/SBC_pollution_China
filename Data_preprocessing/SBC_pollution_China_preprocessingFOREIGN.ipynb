{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "SoS",
    "toc-hr-collapsed": false
   },
   "source": [
    "# SBC_pollution_china data preprocessing: Foreign\n",
    "\n",
    "This notebook has been generated on 2019-10-05 07:45 \n",
    "\n",
    "The objective of this notebook is to YYY\n",
    "\n",
    "## Proposal \n",
    "\n",
    "The proposal is available [here](https://drive.google.com/open?id=1tmSFvdUMXcL3vMKBSNYmf5xe6OEmYNnD)\n",
    "\n",
    "### Equation to estimate\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\text { SO2 emission }_{i k t}=& \\alpha T C Z_{i} \\times \\text { Polluted sectors }_{k} \\times \\text { post } \\\\ &+\\beta T C Z_{i} \\times \\text { Polluted sectors }_{k} \\times \\text { post } \\times \\text { Share SOE }_{k} \\\\ & +\\theta {X}_{i k t}+\\nu_{c i}+\\lambda_{t i} +\\phi_{t c} \\end{aligned}\n",
    "$$\n",
    "\n",
    "city-industry; time-industry and time-city\n",
    "\n",
    "## Global steps \n",
    "\n",
    "The global steps to construct the dataset are the following:\n",
    "\n",
    "\n",
    "- From BigQuery\n",
    "    - Select year 1998-2007 ASIF\n",
    "    \n",
    "- Set parameters:\n",
    "    - Choice of aggregation\n",
    "    - Keep used variables in SO2 dataset\n",
    "    - Exclude cities not operation 7 years in a row\n",
    "    \n",
    "## Data source \n",
    "\n",
    "The data source to construct the dataset are the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "### Big Query Dataset \n",
    " \n",
    " - asif_firm_china \n",
    " - China_city_pollution_98_2007 \n",
    " \n",
    "### Google Cloud Storage Dataset \n",
    " \n",
    "### Google Spreadsheet Dataset \n",
    " \n",
    " - [TCZ_list_china](https://docs.google.com/spreadsheets/d/15bMeS2cMfGfYJkjuY6wOMzcAUWZNRGpO03hZ8rpgv0Q) \n",
    " - [cityname_and_code](https://docs.google.com/spreadsheets/d/1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA) \n",
    " - [provinces_location](https://docs.google.com/spreadsheets/d/1pNMYAannF0g47Vrecu9tzrQ83XaaYmnXJeSuIFwr26g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "SoS"
   },
   "source": [
    "## Destination\n",
    "\n",
    "The new dataset is available from XXX\n",
    "\n",
    "- GS: None\n",
    "- GCS: SBC_pollution_china.gz\n",
    "- BG: SBC_pollution_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "from Fast_connectCloud import connector\n",
    "from GoogleDrivePy.google_drive import connect_drive\n",
    "from GoogleDrivePy.google_platform import connect_cloud_platform\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import Pollution.SBC_pollution as sbc\n",
    "from pathlib import Path\n",
    "import os, re,  requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "gs = connector.open_connection(online_connection = False, \n",
    "\tpath_credential = '/Users/Thomas/Google Drive/Projects/Data_science/Google_code_n_Oauth/Client_Oauth/Google_auth/')\n",
    "\n",
    "service_gd = gs.connect_remote(engine = 'GS')\n",
    "service_gcp = gs.connect_remote(engine = 'GCP')\n",
    "\n",
    "gdr = connect_drive.connect_drive(service_gd['GoogleDrive'])\n",
    "\n",
    "project = 'valid-pagoda-132423'\n",
    "gcp = connect_cloud_platform.connect_console(project = project,\n",
    "\t\t\t\t\t\t\t\t\t\t\t service_account = service_gcp['GoogleCloudP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Load asif_firm_china from Google Big Query\n",
    "\n",
    "Data studio for this dataset available [here](https://drive.google.com/open?id=1ppXfCw73EGVmUQdcM5MI_S9RbtjunhQ_)\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "### Format Data:\n",
    "\n",
    "- Output: in trillions RMB\n",
    "- Employement: in trillions RMB\n",
    "- Fixed Asset: in millions of workers.\n",
    "\n",
    "### Preprocess original data\n",
    "\n",
    "- Rescale output; employment and capital\n",
    "- Remove firms with zeroes values\n",
    "- Aggregate by CIC 2 digits\n",
    "- Keep year 2002-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "#\n",
    "query = (\n",
    "    \"SELECT case \\\n",
    "    WHEN ownership = 'Foreign' THEN 'FOREIGN' \\\n",
    "    WHEN ownership = 'SOE' THEN 'SOE' \\\n",
    "    ELSE 'DOMESTIC' END AS FOREIGN, \\\n",
    "    SUM(output/10000000) as output, \\\n",
    "    SUM(fa_net/10000000) as fa_net, \\\n",
    "    SUM(employment/100000) as employment, \\\n",
    "    newID,Province_en, cityen_correct, geocode4_corr, \\\n",
    "    Lower_location, Larger_location, Coastal, \\\n",
    "    year, cic,indu_2, Short \\\n",
    "    FROM China.asif_firm_china \\\n",
    "    WHERE year >= 2001 AND year < 2008 AND output > 0 AND fa_net > 0 \\\n",
    "    AND employment > 0 \\\n",
    "    GROUP BY newID,Province_en, cityen_correct, geocode4_corr, \\\n",
    "    Lower_location, Larger_location, Coastal, \\\n",
    "    year, FOREIGN, cic,indu_2, Short \"\n",
    ")\n",
    "\n",
    "df_asif_firm_china = gcp.upload_data_from_bigquery(query=query, location=\"US\")\n",
    "df_asif_firm_china.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Load China_city_pollution_98_2007 from Google Big Query\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"SELECT year,cityen, indus_code, ind2, SUM(tso2) as tso2, SUM(tCOD) as tCOD, \\\n",
    "    SUM(twaste_water) as twaste_water \"\n",
    "    \"FROM China.China_city_pollution_98_2007 \"\n",
    "    \"WHERE year > 2001 AND year <= 2007 \"\n",
    "    \"GROUP BY year, cityen,indus_code, ind2\"\n",
    "    \n",
    "\n",
    ")\n",
    "\n",
    "df_China_city_pollution_98_2007 = gcp.upload_data_from_bigquery(\n",
    "    query=query, location='US')\n",
    "df_China_city_pollution_98_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Load TCZ_list_china from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/15bMeS2cMfGfYJkjuY6wOMzcAUWZNRGpO03hZ8rpgv0Q\n",
    "### To change the range\n",
    "\n",
    "sheetid = '15bMeS2cMfGfYJkjuY6wOMzcAUWZNRGpO03hZ8rpgv0Q'\n",
    "sheetname = 'paper'\n",
    "\n",
    "df_TCZ_list_china = gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_TCZ_list_china.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Load cityname_and_code from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA'\n",
    "sheetname = 'final'\n",
    "\n",
    "df_cityname_and_code = gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_cityname_and_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Load provinces_location from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/1pNMYAannF0g47Vrecu9tzrQ83XaaYmnXJeSuIFwr26g\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1pNMYAannF0g47Vrecu9tzrQ83XaaYmnXJeSuIFwr26g'\n",
    "sheetname = 'provinces_location.csv'\n",
    "\n",
    "df_provinces_location = gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_provinces_location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Load China_cities_target_so2 from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/1z3A_I8_StdyNL5O38s2l9hx6W3VR49CGVmaosypjFMA\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1z3A_I8_StdyNL5O38s2l9hx6W3VR49CGVmaosypjFMA'\n",
    "sheetname = 'China_cities_target_so2'\n",
    "\n",
    "df_China_cities_target_so2 = gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_China_cities_target_so2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Workflow\n",
    "\n",
    "In this section, we will construct the dataset, and document each step of the workflow.\n",
    "\n",
    "Please use the following format for the documentation:\n",
    "\n",
    "- `##` Step 1: XXX\n",
    "- `###` (optional) Underlying process description\n",
    "- `##` Step 2: YYY\n",
    "- `###` (optional) Underlying process description\n",
    "\n",
    "Note: **You need to rename the last dataframe `df_final`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Parameters\n",
    "\n",
    "For each change we will modify the original dataset `df_asif_firm_china`\n",
    "\n",
    "Parameteres contains 3 parts:\n",
    "\n",
    "1. Choice of aggregation\n",
    "\n",
    "We are left with two options to aggregate the data:\n",
    "\n",
    "- Indu 2 digits or CIC\n",
    "- `to_group`: Aggregate the data during the first part of the chain: from firm to industry\n",
    "- `to_group_reshape`:  Group the data to create a squared dataframe. The dataset has all industries for each city. If the city does not produce anything, we fill by one. \n",
    "\n",
    "2. Format data\n",
    "\n",
    "Change the format of the city variable in the TCZ data and keep the variables needed in the pollution data\n",
    "\n",
    "3. Exclude city not operating during the 7 years of our analysis: Fill list excluded:\n",
    "\n",
    "- 'Bayannaoer', 'Dingxi', 'Jiuquan', 'Lijiang', 'Lincang', 'Longnan',\n",
    "- 'Luliang', 'Pingliang', 'Qingyang', 'Simao', 'Wulanchabu', 'Wuwei',\n",
    "- 'Zhangye', 'Zhongwei'\n",
    "\n",
    "\n",
    "The program allows the users to pass two parameters. The first parameter `bounce. The exclude firms that enter and leave the market mutliple time through the year. The second parameter, `symmetric` gives the possibility to keep only industries available during both period (10/11th FYP). \n",
    "\n",
    "\n",
    "## Steps \n",
    "\n",
    "The program works as follow:\n",
    "\n",
    "- Step 1: If `bounce` is true, then the program exclude firms bouncing back on and on in the dataset\n",
    "- Step 2: Keep a set of year and create the period dummy variable. The dummy takes the value of `After` all year after 2005. \n",
    "- Step 3: Remove all cities not available every years\n",
    "- Step 4: Prepare the SOE industries. More precisely, the program computes the numbers of SOE firms for each year during 2002-2005 by industry (either HS2 or CIC), and get the average output;capital and labour at the same level. Then, the share by industry is computed.\n",
    "- Step 5: Define the polluted sectors in three difference ways. First, the program computes the average SO2 emission by industries for the year 2002. Then, polluted sectors are defined whether the average is above the national average, the third decile or 68070.\n",
    "- Step 6: Remove the city-industry with null value for SO2 emission\n",
    "- Step 7: Aggregate the control variable at the city-industry-year level\n",
    "- Step 8: Merge TCZ, Share SOE, pollution, pollution by industry\n",
    "- Step 9 (optional): If the user choose to get a symmetric dataset, then the program excludes industries which are not available in both period\n",
    "- Step 10: Remove outliers : when SO2 emissions are below 500 and above 2276992 (about .5 and .95 of the distribution)\n",
    "- Step 11: Create 3 bunches of fixed effect:  city-industry; time-industry and time-city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "# industry_agg = ['indu_2']\n",
    "industry_agg = [\"indu_2\"]\n",
    "\n",
    "years = [\"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\"]\n",
    "\n",
    "\n",
    "order_columns = [\n",
    "    \"year\",\n",
    "    \"Period\",\n",
    "    \"Province_en\",\n",
    "    \"Lower_location\",\n",
    "    \"Larger_location\",\n",
    "    \"Coastal\",\n",
    "    \"cityen\",\n",
    "    \"geocode4_corr\",\n",
    "    \"TCZ_c\",\n",
    "    \"target_c\",\n",
    "    \"effort_c\",\n",
    "    \"industry\",\n",
    "    \"ind2\",\n",
    "    \"Short\",\n",
    "    \"output_fcit\",\n",
    "    \"capital_fcit\",\n",
    "    \"labour_fcit\",\n",
    "    'out_share_for',\n",
    "    'out_share_soe1',\n",
    "    'cap_share_for',\n",
    "    'cap_share_soe1',\n",
    "    'lab_share_for',\n",
    "    'lab_share_soe1',\n",
    "    \"tso2_cit\",\n",
    "    \"tso2_i\",\n",
    "    \"tCOD_cit\",\n",
    "    \"twaste_water_cit\",\n",
    "    \"polluted_di\",\n",
    "    \"polluted_mi\",\n",
    "    \"polluted_thre\",\n",
    "    \"FE_c_i\",\n",
    "    \"FE_t_i\",\n",
    "    \"FE_t_c\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "### 1. Prepapre  `df_asif_firm_china`\n",
    "\n",
    "There is some preprocessing to perform on the original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_asif_firm_china.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "### Run metafunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import Pollution.SBC_pollution as sbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "Note we manually added the foreign share because we changed the TCZ list file, so the number of obs didn't match. Instead, we load the previous data for the paper, construct the share using the metafunction (move the return after the bounce, and then merge back to the original dataset used in the paper\n",
    "\n",
    "```\n",
    "df_final_ = df_final_.merge(\n",
    "    share_for\n",
    "    .assign(industry = lambda x: \n",
    "            x['industry'].astype('int')),\n",
    "    on = 'industry')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_final = sbc.metafunction(df_original=df_asif_firm_china,\n",
    "                        df_TCZ_list_china=df_TCZ_list_china,\n",
    "                        df_China_city_pollution_98_2007=df_China_city_pollution_98_2007,\n",
    "                        df_China_cities_target_so2= df_China_cities_target_so2,\n",
    "                        order_columns=order_columns,\n",
    "                        industry_agg='cic',\n",
    "                        symetric=True,\n",
    "                        bounce=True,\n",
    "                        soe = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_final['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_final['industry'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_final['cityen'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "df_final.to_csv(\n",
    "\t'SBC_pollution_China_foreign.gz',\n",
    "\tsep=',',\n",
    "\theader=True,\n",
    "\tindex=False,\n",
    "\tchunksize=100000,\n",
    "\tcompression='gzip',\n",
    "\tencoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "# Profiling\n",
    "\n",
    "In order to get a quick summary statistic of the data, we generate an HTML file with the profiling of the dataset we've just created. \n",
    "\n",
    "The profiling will be available at this URL after you commit a push to GitHub. \n",
    "\n",
    "**You need to rename the final dataframe `df_final` in the previous section to generate the profiling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "#### make sure the final dataframe is stored as df_final\n",
    "### Overide the default value: \n",
    "#https://github.com/pandas-profiling/pandas-profiling/blob/master/pandas_profiling/config_default.yaml\n",
    "\n",
    "profile = pandas_profiling.ProfileReport(df_final,\n",
    "                                        check_correlation_pearson = False)\n",
    "name_html = \"SBC_pollution_China.html\"\n",
    "profile.to_file(output_file=name_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "# Upload to cloud\n",
    "\n",
    "The dataset is ready to be shared with your colleagues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "### Move to GCS and BigQuery\n",
    "\n",
    "We move the dataset to the following:\n",
    "\n",
    "- **bucket**: *chinese_data*\n",
    "\n",
    "- **Destination_blob**: *Environmental_Statistics_china/Processed_ES*\n",
    "- **name**:  *SBC_pollution_China.gz*\n",
    "- **Dataset**: *China*\n",
    "\n",
    "- **table**: *SBC_pollution_China*\n",
    "\n",
    "### GCS\n",
    "\n",
    "We first need to save *SBC_pollution_China* with `.gz` extension locally then we can move it\n",
    "to GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "source": [
    "## Delete previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "bucket_name = 'chinese_data'\n",
    "destination_blob_name = 'paper_project/SBC_pollution_China_foreign.gz'\n",
    "\n",
    "gcp.delete_blob(bucket_name = bucket_name,\n",
    "                destination_blob_name= destination_blob_name)\n",
    "gcp.delete_table(dataset_name = 'China', name_table = 'SBC_pollution_China_foreign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### First save locally\n",
    "df_final.to_csv(\n",
    "\t'SBC_pollution_China_foreign.gz',\n",
    "\tsep=',',\n",
    "\theader=True,\n",
    "\tindex=False,\n",
    "\tchunksize=100000,\n",
    "\tcompression='gzip',\n",
    "\tencoding='utf-8')\n",
    "\n",
    "### Then upload to GCS\n",
    "bucket_name = 'chinese_data'\n",
    "destination_blob_name = 'paper_project'\n",
    "source_file_name = 'SBC_pollution_China_foreign.gz'\n",
    "gcp.upload_blob(bucket_name, destination_blob_name, source_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Move to bigquery\n",
    "bucket_gcs ='chinese_data/paper_project/SBC_pollution_China_foreign.gz'\n",
    "gcp.move_to_bq_autodetect(dataset_name= 'China',\n",
    "\t\t\t\t\t\t\t name_table= 'SBC_pollution_China_foreign',\n",
    "\t\t\t\t\t\t\t bucket_gcs=bucket_gcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Add data to catalogue\n",
    "\n",
    "Now that the dataset is ready, you need to add the underlying information to the data catalogue. The data catalogue is stored in [Coda](https://coda.io/d/MasterFile-Database_dvfMWDBnHh8/MetaDatabase_suYFO#_ludIZ), more precisely, in the table named `DataSource`. \n",
    "\n",
    "The cells below helps you to push the information directly to the table using Coda API.\n",
    "\n",
    "The columns are as follow:\n",
    "\n",
    "- `Storage`: Define the location of the table\n",
    "    - GBQ, GS, MongoDB\n",
    "- `Theme`: Define a theme attached to the table\n",
    "    - Accountancy, Complexity, Correspondance, Customer_prediction, Distance, Environment, Finance, Macro, Production, Productivity, Survey, Trade\n",
    "- `Database`: Name of the dataset. Use only for GBQ or MongoDB (collection)\n",
    "    - Business, China, Steamforged, Trade\n",
    "- `Path`:A URL with the path of the location of the dataset\n",
    "- `Filename`: Name of the table\n",
    "- `Description`: Description of the table. Be very specific. \n",
    "- `Source_data`: A list of the data sources used to construct the table.\n",
    "- `Link_methodology`: URL linked to the notebook\n",
    "- `Dataset_documentation`: Github repository attached to the table\n",
    "- `Status`: Status of the table. \n",
    "    - `Closed` if the table won't be altered in the future\n",
    "    - `Active` if the table will be altered in the future\n",
    "- `Profiling`: Specify if the user created a Pandas profiling\n",
    "    - `True` if the profiling has been created\n",
    "    - `False` otherwise\n",
    "- `Profiling_URL`: Profiling URL (link to Github). Always located in `Data_catalogue/table_profiling`\n",
    "- `JupyterStudio`: Specify if the user created a notebook to open the studio\n",
    "    - `True` if the notebook has been created\n",
    "    - `False` otherwise\n",
    "- `JupyterStudio_launcher`: Notebook URL (link to Github). Always located in `Notebooks_Ready_to_use_studio`\n",
    "- `Nb_projects`: Number of projects using this dataset. A Coda formula. Do not update this row\n",
    "- `Created on`: Date of creation. A Coda formula. Do not update this row\n",
    "\n",
    "Remember to commit in GitHub to activate the URL link for the profiling and Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "Storage = 'GBQ'\n",
    "Theme = 'Trade' \n",
    "Database = 'China'\n",
    "Description = \"The table is related to the paper on soft budget contrain. The difference with the SBC china is the use of foreign share instead of SOE share\"\n",
    "Filename = 'SBC_pollution_China_foreign'\n",
    "Status = 'Active'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "Source_data = [\n",
    "    \"asif_firm_china\",\n",
    "    \"China_city_pollution_98_2007\",\n",
    "    \"TCZ_list_china\",\n",
    "    \"cityname_and_code\",\n",
    "    'province_location',\n",
    "    'China_cities_target_so2'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "The next cell pushes the information to [Coda](https://coda.io/d/MasterFile-Database_dvfMWDBnHh8/Test-API_suDBp#API_tuDK4)\n",
    "The next cell pushes the information to Coda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "regex = r\"(.*)/(.*)\"\n",
    "path = os.getcwd()\n",
    "parent_path = Path(path).parent\n",
    "test_str = str(parent_path)\n",
    "matches = re.search(regex, test_str)\n",
    "github_repo = matches.group(2)\n",
    "\n",
    "Profiling = True\n",
    "if Profiling:\n",
    "    Profiling_URL = 'http://htmlpreview.github.io/?https://github.com/' \\\n",
    "    'thomaspernet/{}/blob/master/Data_catalogue/table_profiling/{}.html'.format(github_repo,\n",
    "                                                                               Filename)\n",
    "else:\n",
    "    Profiling_URL = ''\n",
    "JupyterStudio = False\n",
    "if JupyterStudio:\n",
    "    JupyterStudio_URL = '\"https://mybinder.org/v2/gh/thomaspernet/{0}/' \\\n",
    "    'master?filepath=Notebooks_Ready_to_use_studio%2F{1}_studio.ipynb'.format(github_repo, Filename)\n",
    "else:\n",
    "    JupyterStudio_URL = ''\n",
    "### BigQuery only \n",
    "path_url = 'https://console.cloud.google.com/bigquery?project=valid-pagoda-132423' \\\n",
    "'&p=valid-pagoda-132423&d=China&t={}&page=table'.format(Filename)\n",
    "\n",
    "Link_methodology = 'https://mybinder.org/v2/gh/thomaspernet/{0}/' \\\n",
    "    'master?filepath=Data_preprocessing%2F{1}.ipynb'.format(github_repo, Filename)\n",
    "Dataset_documentation = 'https://github.com/thomaspernet/{}'.format(github_repo)\n",
    "\n",
    "to_add = {\n",
    "    'Storage': Storage,\n",
    "    'Theme': Theme,\n",
    "    'Database': Database,\n",
    "    'Path_url': path_url,\n",
    "    'Filename': Filename,\n",
    "    'Description': Description,\n",
    "    'Source_data': Source_data,\n",
    "    'Link_methodology': Link_methodology,\n",
    "    'Dataset_documentation': Dataset_documentation,\n",
    "    'Status': Status,\n",
    "    'Profiling_URL': Profiling_URL,\n",
    "    'JupyterStudio_launcher': JupyterStudio_URL\n",
    "\n",
    "}\n",
    "cols= []\n",
    "for key, value in to_add.items():\n",
    "    coda = {\n",
    "    'column': key,\n",
    "    'value':value\n",
    "    }\n",
    "    cols.append(coda)\n",
    "    \n",
    "with open('token_coda.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "token = data[0]['token'] \n",
    "headers = {\"Authorization\": \"Bearer \" + token}\n",
    "params = {\n",
    "  'isOwner': True\n",
    "}\n",
    "\n",
    "uri = f'https://coda.io/apis/v1beta1/docs/vfMWDBnHh8/tables/grid-HgpAnIEhpP/rows'\n",
    "payload = {\n",
    "  'rows': [\n",
    "    {\n",
    "      'cells': cols,\n",
    "    },\n",
    "  ],\n",
    "}\n",
    "req = requests.post(uri, headers=headers, json=payload)\n",
    "req.raise_for_status() # Throw if there was an error.\n",
    "res = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "kernel": "python3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "sos"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.22.0"
  },
  "sos": {
   "kernels": [
    [
     "python3",
     "python3",
     "python3",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
