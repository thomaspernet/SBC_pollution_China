{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asif_firm_china data preprocessing\n",
    "\n",
    "This notebook has been generated on 2019-08-06 08:40 \n",
    "\n",
    "The objective of this notebook is to prepare ASIF dataset. There are issues with year 2008 & 2009. We will cover it into more details in the section *Data prep*. \n",
    "\n",
    "DEPRECATED: (Are you reading for the pain to translate STATA do file to Python? Yes.. Let's do it.)\n",
    "\n",
    "We changed the stata file to csv. We did it toi translate the STATA 13 unicode to modern chinese.\n",
    "\n",
    "\n",
    "\n",
    "We follow this [do file](https://feb.kuleuven.be/public/u0044468//CHINA/appendix/Match%20Firms%20Over%20Time.do)\n",
    "\n",
    "The paper related to the data construction is [Challenges of working with the Chinese NBS firm-level data](https://docs.google.com/file/d/16agSbxO7cYuEn1v2bvw16ZRAx9gg7-Zm/edit)\n",
    "\n",
    "The Raw data has been processed following this Notebook, [Asif_raw_to_csv_preprocessing](https://nbviewer.jupyter.org/github/thomaspernet/DataLab-JupyterNotebooks/blob/master/Notebook_dataprocessing/Asif_raw_to_csv_preprocessing.ipynb)\n",
    "\n",
    "Variables names 1998-2009 available [here](https://docs.google.com/spreadsheets/d/1gfdmBKzZ1h93atSMFcj_6YgLxC7xX62BCxOngJwf7qE/edit#gid=1504397597) \n",
    "\n",
    "## Global steps \n",
    "\n",
    "The global steps to construct the dataset are the following:\n",
    "\n",
    "\n",
    "\n",
    "## Data source \n",
    "\n",
    "The data source to construct the dataset are the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "\n",
    " ### Big Query Dataset \n",
    " \n",
    " ### Google Cloud Storage Dataset \n",
    " \n",
    " - asif_year_2008 \n",
    " - asif_year_ \n",
    " ### Google Spreadsheet Dataset \n",
    " \n",
    " - [cityname_and_code](https://docs.google.com/spreadsheets/1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA) \n",
    " - [provinces_location](https://docs.google.com/spreadsheets/1pNMYAannF0g47Vrecu9tzrQ83XaaYmnXJeSuIFwr26g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Destination\n",
    "\n",
    "The new dataset is available from XXX\n",
    "\n",
    "- GS: None\n",
    "- GCS: asif_firm_china.gz\n",
    "- BG: asif_firm_china"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from Fast_connectCloud import connector\n",
    "from GoogleDrivePy.google_drive import connect_drive\n",
    "from GoogleDrivePy.google_platform import connect_cloud_platform\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gs = connector.open_connection(online_connection = False, \n",
    "\tpath_credential = '/Users/Thomas/Google Drive/Projects/Data_science/Google_code_n_Oauth/Client_Oauth/Google_auth/')\n",
    "\n",
    "service_gd = gs.connect_remote(engine = 'GS')\n",
    "service_gcp = gs.connect_remote(engine = 'GCP')\n",
    "\n",
    "gdr = connect_drive.connect_drive(service_gd['GoogleDrive'])\n",
    "\n",
    "project = 'valid-pagoda-132423'\n",
    "gcp = connect_cloud_platform.connect_console(project = project,\n",
    "\t\t\t\t\t\t\t\t\t\t\t service_account = service_gcp['GoogleCloudP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "\n",
    "## Load asif_firm_china from Google Cloud Storage\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#df_load_data = pd.DataFrame()\n",
    "#for dataset in [\n",
    "#    'asif_year_1998.gz', 'asif_year_1999.gz',\n",
    "#    'asif_year_2000.gz', 'asif_year_2001.gz',\n",
    "#    'asif_year_2002.gz', 'asif_year_2003.gz',\n",
    "#    'asif_year_2004.gz', 'asif_year_2005.gz',\n",
    "#    'asif_year_2006.gz', 'asif_year_2007.gz',\n",
    "   # 'asif_year_2008.gz', 'asif_year_2009.gz'\n",
    "#]:\n",
    "#    gcp.download_blob(bucket_name = 'chinese_data',\n",
    "#                  destination_blob_name = 'Panel_china/Asif_panel_china/Raw_',\n",
    "#                  source_file_name = dataset)\n",
    "#                  \n",
    "#    df_temp = pd.read_csv(dataset,\n",
    "#                          compression='gzip',\n",
    "#                          header=0,\n",
    "#                          sep=',',\n",
    "#                          quotechar='\"',\n",
    "#                          error_bad_lines=False)\n",
    "#    df_load_data = df_load_data.append(df_temp)\n",
    "#df_load_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "\n",
    "## Load cityname_and_code from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### Please go here https://docs.google.com/spreadsheets/d/1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA'\n",
    "sheetname = 'final'\n",
    "\n",
    "df_cityname_and_code = gdr.upload_data_from_spreadsheet(sheetID = sheetid, sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_cityname_and_code.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "\n",
    "## Load provinces_location from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### Please go here https://docs.google.com/spreadsheets/d/1pNMYAannF0g47Vrecu9tzrQ83XaaYmnXJeSuIFwr26g\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1pNMYAannF0g47Vrecu9tzrQ83XaaYmnXJeSuIFwr26g'\n",
    "sheetname = 'provinces_location.csv'\n",
    "\n",
    "df_provinces_location = gdr.upload_data_from_spreadsheet(sheetID = sheetid, sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_provinces_location.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Load CIC_industry_name from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/1j6WnAV3AcUQ4yFw8BibzJ5yrzR6nXnOMelnNHPDZBQU\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1j6WnAV3AcUQ4yFw8BibzJ5yrzR6nXnOMelnNHPDZBQU'\n",
    "sheetname = 'industry_name'\n",
    "\n",
    "df_CIC_industry_name = gdr.upload_data_from_spreadsheet(sheetID = sheetid, sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_CIC_industry_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "In this section, we will construct the dataset, and document each step of the workflow.\n",
    "\n",
    "Please use the following format for the documentation:\n",
    "\n",
    "- `##` Step 1: XXX\n",
    "- `###` (optional) Underlying process description\n",
    "- `##` Step 2: YYY\n",
    "- `###` (optional) Underlying process description\n",
    "\n",
    "Note: **You need to rename the last dataframe `df_final`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Step 1: Prepare data 1998-2007\n",
    "\n",
    "For year 2008, we have ion hand two differents datasets. None of them look alike. We use the second one because it has all the observations BUT not the firm's ID. The first one missing 70% of the data\n",
    "\n",
    "Variables kept: \n",
    "\n",
    "|  Brands          | 2008       | 2009               |\n",
    "| ---------------- | ---------- | ------------------ |\n",
    "| bdat             | B131/开业(成立)时间--年       | 开业(成立)时间--年        |\n",
    "| cic              | B07  / 行业代码      | 行业代码               |\n",
    "| dq               | B05 /新行政代码 (6 digits)       |                    |\n",
    "| e_HMT            | E06        | -                  |\n",
    "| e_collective     | E03        | -                  |\n",
    "| e_foreign        | E02        | -                  |\n",
    "| e_individual     | E05        | -                  |\n",
    "| e_legal_person   | E04        | -                  |\n",
    "| e_state          | E01        | -                  |\n",
    "| employment       | B2001  /全部从业人员年平均人数    | 全部从业人员年平均人数        |\n",
    "| export           | V12  /出口交货值      | 出口交货值              |\n",
    "| fa_net           |     固定资产合计       |                    |\n",
    "| fa_original      |            |                    |\n",
    "| a_dep            |            |                    |\n",
    "| c_dep            |            |                    |\n",
    "| id               | B00        | 法人代码               |\n",
    "| input            |            |                    |\n",
    "| legal_person     | B03        |                    |\n",
    "| name             |    法人单位        |                    |\n",
    "| new_product      |            |                    |\n",
    "| output           | V08 /工业总产值（当年价格       | 工业总产值(当年价格)        |\n",
    "| phone            | B062 /电话号码      | 电话号码               |\n",
    "| product1_        |   主营产品1         |                    |\n",
    "| profit           | OS25  /营业利润     | 营业利润               |\n",
    "| revenue          | OS03   /主营业务收入    | 主营业务收入             |\n",
    "| street           | B053    /街道办事处   | 街道办事处              |\n",
    "| town             | B051   /乡（镇）    | 乡（镇）               |\n",
    "| type             | B10   /登记注册类型     | 登记注册类型             |\n",
    "| va               | V08 - OS06 | 工业总产值(当年价格) - 营业费用 |\n",
    "| village          | B052  /街（村）、门牌号     | 街（村）、门牌号           |\n",
    "| wage             | OS35       |                    |\n",
    "| zip              | B040  /邮政编码     | 邮政编码               |\n",
    "\n",
    "\n",
    "**Issues**\n",
    "\n",
    "- step 10: match by firm ID\n",
    "    - deal with duplicates of IDs (there are a few firms that have same IDs)\n",
    "    \n",
    "    \n",
    "We can import all the variables since all the files in Storage have each column respectively. Even thought, they don't have value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "df_ASIF = pd.DataFrame()\n",
    "\n",
    "dic_year = {}\n",
    "\n",
    "dtypes = {\n",
    "    'id':'str',\n",
    "    'year':'str',\n",
    "    'bdat':'str',\n",
    "    'citycode':'str',\n",
    "    'type':'str',\n",
    "    'cic':'str',\n",
    "    'zip':'str', \n",
    "    'phone':'str',\n",
    "    'town':'str',\n",
    "    'product1_':'str',\n",
    "    'legal_person':'str',\n",
    "    'output':np.int32,\n",
    "    'export':np.int32, \n",
    "    'revenue':np.float32,\n",
    "    'profit':np.int32,                \n",
    "    'employment':np.int32, \n",
    "    'e_HMT':np.float32,\n",
    "    'e_collective':np.float32,\n",
    "    'e_foreign':np.float32,\n",
    "    'e_individual':np.float32,\n",
    "    'e_legal_person':np.float32,\n",
    "    'e_state':np.float32,\n",
    "    'wage':np.float32,\n",
    "    'input':np.float32,\n",
    "    'va':np.float32\n",
    "    \n",
    "}\n",
    "\n",
    "for year in tqdm.tqdm(range(1998, 2008, 1)):\n",
    "    #print(year)\n",
    "    var = \"df_{0}\".format(year)    \n",
    "    df_ = pd.read_csv(\n",
    "        'asif_year_{0}.gz'.format(year),\n",
    "        dtype = dtypes,\n",
    "        compression='gzip',\n",
    "        header=0,\n",
    "        sep=',',\n",
    "        quotechar='\"',\n",
    "        error_bad_lines=False\n",
    "        )\n",
    "    dic_year.update({var : df_})\n",
    "    df_ASIF = df_ASIF.append(df_, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dic_ = {\n",
    "    'year': [\"1998\",\n",
    "             \"1999\",\n",
    "             \"2000\",\n",
    "             \"2001\",\n",
    "             \"2002\",\n",
    "             \"2003\",\n",
    "             \"2004\",\n",
    "             \"2005\",\n",
    "             \"2006\",\n",
    "             \"2007\"\n",
    "             ],\n",
    "    'count_brand':\n",
    "        [165118,\n",
    "         162033,\n",
    "         162883,\n",
    "         169030,\n",
    "         181557,\n",
    "         196222,\n",
    "         279092,\n",
    "         271835,\n",
    "         301961,\n",
    "         336768\n",
    "         ],\n",
    "\n",
    "    'output_brand':\n",
    "    [\n",
    "        6.77,\n",
    "        7.27,\n",
    "        8.57,\n",
    "        9.41,\n",
    "        11.08,\n",
    "        14.23,\n",
    "        20.16,\n",
    "        25.16,\n",
    "        31.66,\n",
    "        40.52\n",
    "    ],\n",
    "    'va_brand':\n",
    "    [\n",
    "        1.94,\n",
    "        2.16,\n",
    "        2.54,\n",
    "        2.79,\n",
    "        3.30,\n",
    "        4.20,\n",
    "        6.62,\n",
    "        7.22,\n",
    "        9.11,\n",
    "        11.70\n",
    "    ],\n",
    "    'employment_brand':\n",
    "    [\n",
    "        56.44,\n",
    "        58.05,\n",
    "        53.68,\n",
    "        52.97,\n",
    "        55.21,\n",
    "        57.49,\n",
    "        66.27,\n",
    "        68.96,\n",
    "        73.58,\n",
    "        78.75\n",
    "\n",
    "    ]\n",
    "}\n",
    "brand = pd.DataFrame(dic_).set_index('year')\n",
    "count = df_ASIF.groupby('year')['id'].count().rename('count')\n",
    "output = (df_ASIF.groupby('year')['output'].sum()/ 1000000000).round(1)\n",
    "va = (df_ASIF.groupby('year')['va'].sum()/ 1000000000).round(1)\n",
    "emp = (df_ASIF.groupby('year')['employment'].sum()/ 1000000).round(2)\n",
    "\n",
    "asif = pd.concat(\n",
    "    [brand, count, output, va, emp],\n",
    "    axis=1).reindex(\n",
    "    columns=['count_brand', 'count',\n",
    "             'output_brand', 'output',\n",
    "             'va_brand', 'va',\n",
    "             'employment_brand', 'employment'])\n",
    "asif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF.groupby(['year']).size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "This is an ID test to make sure this ID has always 11 obs through the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF.loc[lambda x:x['id'].isin(['209752211'])][\n",
    "    ['year', 'id', 'name', 'citycode', 'output', 'phone']\n",
    "].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Create matching variables\n",
    "\n",
    "1. match by the names of legal person representatives\n",
    "\n",
    "Stata codes \n",
    "\n",
    "```\n",
    "replace legal_person`i'=\".\" if legal_person`i'==\"\"\n",
    "gen code1=legal_person`i'+substr(dq`i',1,4) \n",
    "```\n",
    "\n",
    "2. match by phone number + city code\n",
    "\n",
    "Stata codes \n",
    "\n",
    "```\n",
    "replace phone`i'=\".\" if phone`i'==\"\"\n",
    "gen code2=substr(dq`i',1,4)+substr(cic`i',1,3)+phone`i'\n",
    "```\n",
    "\n",
    "3. match by code = founding year + geographic code + industry code + name of town + name of main product\n",
    "\n",
    "Stata codes \n",
    "\n",
    "```\n",
    "replace town`i'=\".\" if town`i'==\"\"\n",
    "replace product1_`i'=\".\" if product1_`i'==\"\"\n",
    "gen code3=bdat`i'+substr(dq`i',1,6)+substr(cic`i',1,4)+town`i'+product1_`i'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add city and industry\n",
    "\n",
    "We add city and industry now so that we get a consistent city code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def multiple_city(df, cityvar = 'citycode'):\n",
    "    temp_multi = (df\n",
    "                  .groupby(['id'])[cityvar]\n",
    "                  .nunique()\n",
    "                  .sort_values()\n",
    "                  .reset_index()\n",
    "                  .rename(columns = {'citycode': 'count'})    \n",
    "             )\n",
    "    \n",
    "    return temp_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp_multi = multiple_city(df = df_ASIF)\n",
    "temp_multi.groupby('count')['id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "In the following ID, the firm in 2004 went top  Huzhou, but the firm's name is Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF[df_ASIF['id'] == '147133481'][['year', 'id',\n",
    "                                       'name', 'citycode',\n",
    "                                       'output', 'phone']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "We extract the city name from the company's name, when possible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_list = df_cityname_and_code['citycn'].tolist()\n",
    "df_ASIF['city_prod'] = df_ASIF['name'].str.extract(r\"(?=(\" + '|'.join(raw_list) +\n",
    "                                             r\"))\")\n",
    "missing_cities_before = df_ASIF['city_prod'].isnull().sum()\n",
    "print('Sum missing cities {}'.format(missing_cities_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Now the firm's is in Shanghai, not Hezhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF[df_ASIF['id'] == '147133481'][['year', 'id',\n",
    "                                       'name', 'citycode',\n",
    "                                       'city_prod',\n",
    "                                       'output',\n",
    "                                       'phone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF[df_ASIF['id'] == '114591099'][['year', 'id',\n",
    "                                       'name', 'citycode',\n",
    "                                       'city_prod',\n",
    "                                       'output',\n",
    "                                       'phone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF.loc[lambda x:x['id'].isin(['209752211'])][\n",
    "    ['year', 'id', 'name', 'citycode', 'output', 'phone']\n",
    "].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Test -> merge `df_cityname_and_code` with `city_prod`  and `citycn` to get the `geocode4_corr` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#test_m = df_ASIF.merge(\n",
    "#    df_cityname_and_code[['citycn',\n",
    "#                          'geocode4_corr'\n",
    "#                         ]\n",
    "#                        ].drop_duplicates(\n",
    "#        subset = 'citycn'\n",
    "#    ),\n",
    "#    left_on= 'city_prod',\n",
    "#    right_on = 'citycn',\n",
    "#    how = 'left',\n",
    "#indicator = True)\n",
    "#test_m.shape\n",
    "#test_m.groupby(['_merge'])['_merge'].count()\n",
    "#test_m = test_m.drop(columns = ['_merge', 'citycn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Add city\n",
    "\n",
    "1. Merge `citycode` with `df_cityname_and_code`\n",
    "2. Merge `Province_cn` with `prov2013`\n",
    "\n",
    "\n",
    "Warning, since we don't match the `citycn`, we need to drop the duplicates `citycn`. It's to avoid this:\n",
    "\n",
    "```\n",
    "5001\t5001\t重庆市\tChongqing\t重庆\tChongqing\t重庆市\tChongqing\n",
    "5001\t5001\t重庆\tChongqing\t重庆\tChongqing\t重庆市\tChongqing\n",
    "5002\t5001\t重庆市\tChongqing\t重庆\tChongqing\t重庆市\tChongqing\n",
    "```\n",
    "To add rows if many city name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_cityname_and_code_ = df_cityname_and_code.drop(columns = \n",
    "                                                  ['citycn',\n",
    "                                                   'cityen']).drop_duplicates()\n",
    "df_cityname_and_code_.loc[lambda x : x['geocode4_corr'].isin(['5001'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city = df_ASIF.merge(df_cityname_and_code_,\n",
    "               left_on = 'citycode',\n",
    "               right_on = 'extra_coda',\n",
    "               how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city.loc[lambda x:x['id'].isin(['209752211'])][\n",
    "    ['year', 'id', 'name', 'extra_coda','citycode', 'output', 'phone',\n",
    "    'geocode4_corr']\n",
    "].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### 101326 observation unmatched\n",
    "df_ASIF.shape[0] - df_ASIF_city.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city[df_ASIF_city['id'] == '147133481'][[\n",
    "    'year', 'id', 'name', 'citycode','geocode4_corr',\n",
    "    'city_prod',\n",
    "    'output', 'phone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city.loc[lambda x: \n",
    "                 (~x['city_prod'].isin([np.nan]))\n",
    "                 &\n",
    "                 (x['city_prod'] != x['citycn_correct'])\n",
    "                ][[\n",
    "    'year', 'id', 'name', 'citycode','geocode4_corr',\n",
    "    'city_prod', \n",
    "    'output', 'phone']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "There are 8925 firms with different name and city, but only 37 have differents `citycode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp_check = df_ASIF_city.loc[lambda x: \n",
    "                 (~x['city_prod'].isin([np.nan]))\n",
    "                 &\n",
    "                 (x['city_prod'] != x['citycn_correct'])\n",
    "                ]#['id'].nunique()\n",
    "(temp_check\n",
    " .groupby('id')['geocode4_corr']\n",
    " .nunique()\n",
    " .sort_values(ascending = False)\n",
    " .reset_index()\n",
    " .groupby('geocode4_corr').count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "We drop these 37 firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "toremove = (temp_check\n",
    " .groupby('id')['geocode4_corr']\n",
    " .nunique()\n",
    " .sort_values(ascending = False)\n",
    " .loc[lambda x: x ==2]\n",
    " .index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_ = df_ASIF_city.loc[lambda x: ~x['id'].isin(toremove)]\n",
    "df_ASIF_city_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_.loc[lambda x:x['id'].isin(['209752211'])][\n",
    "    ['year', 'id', 'name', 'citycode', 'output', 'phone']\n",
    "].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Remember, for the city, we need to exclude:\n",
    "\n",
    "- [Spreadsheet](https://docs.google.com/spreadsheets/d/1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA/edit#gid=304413184)\n",
    "- `extra_coda`, `citycn`&`cityen`: Not unique name ie: (巴彦淖尔; 巴彦淖尔盟)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for city in ['geocode4_corr','citycn_correct',\n",
    "             'cityen_correct']:\n",
    "    print('The variable {0} has {1} unique values'.format(city,\n",
    "                                                          df_ASIF_city_[city].nunique()\n",
    "                                                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_ = df_ASIF_city_.drop(columns = [\n",
    "                                            'city_prod',\n",
    "                                           'extra_coda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov = df_ASIF_city.merge(df_provinces_location,\n",
    "               left_on = 'Province_cn',\n",
    "               right_on = 'prov2013',\n",
    "               how = 'inner')\n",
    "df_ASIF_city_prov = df_ASIF_city_prov.drop(columns =\n",
    "                                           ['prov2013', 'Provinces'])\n",
    "df_ASIF_city_prov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Some city like \n",
    "\n",
    "1507\t1507\t呼伦贝尔\tHulunbeier\t呼伦贝尔\tHulunbeier\t内蒙古自治区\tInner Mongolia Autonomous Region\n",
    "1507\t1507\t呼伦贝尔盟\tHulun Buir League\t呼伦贝尔\tHulunbeier\t内蒙古自治区\tInner Mongolia Autonomous Region\n",
    "\n",
    "have the same codes but two city names, we need to drop the duplocates to remove the duplicates from the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_ = df_ASIF_city_prov.drop_duplicates()\n",
    "df_ASIF_city_prov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Double check multiple cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp_multi = multiple_city(df = df_ASIF_city_prov_,\n",
    "                          cityvar = 'geocode4_corr')\n",
    "temp_multi.groupby('geocode4_corr')['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_[df_ASIF_city_prov_['id'] == '245487275'][\n",
    "    ['year', 'id', 'name','citycode' , 'geocode4_corr', 'output', 'phone']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Remove the 3 firms with 3 locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_ = df_ASIF_city_prov.merge(\n",
    "    temp_multi.rename(columns = {'geocode4_corr': 'count'})\n",
    ").loc[lambda x :x['count'] == 1]\n",
    "df_ASIF_city_prov_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    df_ASIF.groupby('year')['id'].count(),\n",
    "    df_ASIF_city_prov_.groupby('year')['id'].count()\n",
    "], axis = 1).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### New matching var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#df_ASIF['legal_person'] = df_ASIF['legal_person'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# ARCHIVE - Some issue with the data\n",
    "\n",
    "- Need to correct chinese name:\n",
    " \n",
    " Cell below show same character but different spelling\n",
    " \n",
    " - ID: HB9432022\t\n",
    "    - name: 衡水市潴泷万向有限公司\n",
    "- ID: HB9432225\t\n",
    "    - name: 衡水市潴龙万向有限公司\n",
    "\n",
    "\n",
    "below, there are two differents firms, but in 2005, the ID is switched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_[(df_ASIF_city_prov_['id'] == 'HB9432225') |\n",
    "#         (df_ASIF_city_prov_['id'] == 'HB9432022')\n",
    "#        ][\n",
    "#    ['year', 'id', 'name', 'citycode', 'output', 'phone']\n",
    "#].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Add name in pinyin, more reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_['namepinyin'] = df_ASIF_city_prov_['name'].apply(lambda x: pinyin.get(x,\n",
    "#                                                      format=\"numerical\")\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Number of unique id -> 588,011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Number of unique name -> 718,077. Multi name firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_['namepinyin'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idphone = (df_ASIF_city_prov_[['id','phone', 'namepinyin', 'geocode4_corr']]\n",
    "#             .drop_duplicates(#subset=['phone'],\n",
    "#                              #keep=False\n",
    "#                             )\n",
    "#             .rename(columns = {'phone':'dup_phone'})\n",
    "#            )\n",
    "#idphone.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idphone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Get max rows ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "count the number of name rows by id name, and the maximum count will be the ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idnamecity = (df_ASIF_city_prov_[['id', 'namepinyin', 'geocode4_corr']]\n",
    "#              .groupby(['id', 'namepinyin', 'geocode4_corr'])\n",
    "#              .size()\n",
    "#              .reset_index(name='counts')\n",
    "              #.sort_values(by = ['namepinyin', 'counts'])\n",
    "#          )\n",
    "#idnamecity['max'] = idnamecity.groupby(['namepinyin'])['counts'].transform('max') \n",
    "#idnamecity = idnamecity[idnamecity['counts'] == idnamecity['max']]\n",
    "#idnamecity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idnamecity[(idnamecity['id'] == 'HB9432225') |\n",
    "#         (idnamecity['id'] == 'HB9432022')\n",
    "#        ]\n",
    "#衡水市潴泷万向有限公司\n",
    "#河北程杰汽车转向机械制造有限公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#namephone = (df_ASIF_city_prov_[['phone', 'namepinyin', 'geocode4_corr']]\n",
    "#             .drop_duplicates(#subset=['phone'],\n",
    "#                              #keep=False\n",
    "#                             )\n",
    "#             .rename(columns = {'phone':'dup_phone'})\n",
    "#            )\n",
    "#namephone.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#namephone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test = idnamecity.merge(namephone, \n",
    "#                on = ['namepinyin', 'geocode4_corr'],\n",
    "#                how = 'inner').drop(columns  = 'max')\n",
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test[(test['id'] == 'HB9432225') |\n",
    "#         (test['id'] == 'HB9432022')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Number of firm by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#(test[['id', 'counts']]\n",
    "# .drop_duplicates()\n",
    "# .groupby(['id'])['counts']\n",
    "# .sum()\n",
    "# .reset_index()\n",
    "# .sort_values(by = 'counts')\n",
    "# .groupby('counts')\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_.loc[lambda x:x['id'].isin(['169424423'])][\n",
    "#    ['year', 'id', 'name', 'citycode', 'output', 'phone']\n",
    "#].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Archive\n",
    "\n",
    "Now we keep the Firms with no ID and we find them back with Name and Phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idNan = df_ASIF_city_prov_[df_ASIF_city_prov_['id'].isin([np.nan])][[\n",
    "##                                                                    #'year',\n",
    "#                                                                     'geocode4_corr',\n",
    "#                                                                    'namepinyin',\n",
    "#                                                                    'phone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idNan.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idNan['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "merge with name, city and phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#year_0809 = test.merge(idNan,\n",
    "#          left_on = ['namepinyin',\n",
    "#                'geocode4_corr',\n",
    "#                'dup_phone'],\n",
    "#           right_on = ['namepinyin',\n",
    "#                'geocode4_corr',\n",
    "#                'phone'],\n",
    "#           how = 'right',\n",
    "#           indicator=True\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#year_0809.groupby('_merge')['_merge'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#year_0809.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "301719 firms matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#matched_0809 = year_0809[year_0809['_merge'] == 'both']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Find the unmatched with name only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#unmatched_0809 = year_0809[year_0809['_merge'] == 'right_only'].drop(columns=[\n",
    "#    '_merge', 'id', 'counts', 'namepinyin', 'dup_phone'\n",
    "    \n",
    "    #'dup_phone'\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test_1 = test.merge(unmatched_0809,\n",
    "#          left_on=['dup_phone',\n",
    "#                'geocode4_corr'],\n",
    "#           right_on=['phone',\n",
    "#                'geocode4_corr'],\n",
    "#           how='right',\n",
    "#           indicator=True\n",
    "#          )#.groupby('_merge').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#matched_0809_2 = test_1[test_1['_merge'] == 'both'].drop(columns = ['_merge', 'phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#matched_0809 = matched_0809.drop(columns = ['_merge', 'phone']).append(matched_0809_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#matched_0809.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#matched_0809.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#IDnew = test.append(matched_0809).drop_duplicates()\n",
    "#IDnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#temp = test == IDnew\n",
    "#test.equals(IDnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import random \n",
    "#import string\n",
    "#def randomID():\n",
    "#    random_ = ''.join([random.choice(string.ascii_letters+\n",
    "#                                     string.digits) for n in range(30)])\n",
    "#    return random_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID = (test\n",
    "#         .groupby('id')\n",
    "#         .apply(lambda x: randomID())\n",
    "#         .rename(\"newID\")\n",
    "#         .reset_index()\n",
    "#         .merge(test, \n",
    "#                  on = 'id')\n",
    "#         .rename(columns = {'dup_phone': 'phone'})\n",
    "#        )\n",
    "#newID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID[(newID['id'] == 'HB9432225') |\n",
    "#         (newID['id'] == 'HB9432022')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test = df_ASIF_city_prov_[(df_ASIF_city_prov_['id'] == 'HB9432225') |\n",
    "#         (df_ASIF_city_prov_['id'] == 'HB9432022')\n",
    "#        ][['year', 'id', 'name','output', 'phone', 'geocode4_corr',\n",
    "# 'namepinyin']].sort_values(by = ['id','year', 'name'])\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test_ = test.merge(newID, on = ['id', 'geocode4_corr', 'namepinyin', 'phone'],\n",
    "#           how='left', indicator=True)\n",
    "\n",
    "#unmatched = test_[test_['_merge'] == 'left_only'].drop(\n",
    "#            columns=['_merge', 'newID',\n",
    "#                     # 'counts'\n",
    "#                     ]\n",
    "#        )\n",
    "#newID_ =  newID.loc[lambda x:x['id'].isin(unmatched['id'].to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#unmatched.merge(newID_, on = ['namepinyin', 'phone'], suffixes = ('_old', '_new'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Merge 98-07\n",
    "\n",
    "Need to make sure max year by ID is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df9807 = df_ASIF_city_prov_[~df_ASIF_city_prov_['year'].isin(['2008', '2009'])]\n",
    "#df9807.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def merge_(list_merge, df, newID, remove_=False):\n",
    "    \"\"\"\n",
    "    List_merge: List of list containint the variables to\n",
    "    merge with.\n",
    "    Output is a dataframe with matched observation\n",
    "    remove_: Avoid to have many firm's id for a single year\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge High level:\n",
    "\n",
    "    unmatched = df\n",
    "    newID_ = newID.loc[lambda x:x['id'].isin(unmatched['id'].to_list())]\n",
    "\n",
    "    final_append = pd.DataFrame()\n",
    "    size_ = df.shape[0]\n",
    "\n",
    "    for m in list_merge:\n",
    "\n",
    "        if unmatched.shape[0] == size_:\n",
    "\n",
    "            merge = unmatched.merge(newID_,\n",
    "                                    on=m,\n",
    "                                    how='left',\n",
    "                                    indicator=True\n",
    "                                    )\n",
    "        else:\n",
    "            merge = unmatched.merge(newID_,\n",
    "                                    on=m,\n",
    "                                    how='inner',\n",
    "                                    indicator=True,\n",
    "                                    suffixes=('_old', '_new')\n",
    "                                    )\n",
    "        newID_ = newID_.loc[lambda x:x['id'].isin(unmatched['id'].to_list())]\n",
    "\n",
    "        # Print\n",
    "        print(merge.groupby('_merge')['_merge'].count())\n",
    "\n",
    "        # select unmatched\n",
    "        unmatched = merge[merge['_merge'] == 'left_only'].drop(\n",
    "            columns=['_merge', 'newID',\n",
    "                     # 'counts'\n",
    "                     ]\n",
    "        )\n",
    "\n",
    "        # keep newmatch\n",
    "\n",
    "        match_ = merge[merge['_merge'] == 'both'].drop(\n",
    "            columns=['_merge',\n",
    "                     # 'counts'\n",
    "                     ]\n",
    "        )\n",
    "\n",
    "        final_append = final_append.append(match_, sort=False)\n",
    "\n",
    "    # final_append = final_append.drop_duplicates()\n",
    "\n",
    "    if remove_:\n",
    "\n",
    "        size_ = (final_append\n",
    "                 .drop_duplicates()\n",
    "                 .groupby('newID')\n",
    "                 .size()\n",
    "                 .reset_index(name='size')\n",
    "                 )\n",
    "\n",
    "        final_append = final_append.merge(size_, on='newID')\n",
    "        final_append = (final_append\n",
    "                        .loc[lambda x: x['size'].isin([\n",
    "                            1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "                        ])]\n",
    "                        .drop(columns=[\n",
    "                            'count',\n",
    "                            'namepinyin',\n",
    "                            'newID',\n",
    "                            'counts',\n",
    "                            'size'\n",
    "                        ])\n",
    "                        )\n",
    "\n",
    "    return final_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#list_merge = [\n",
    "#    [\n",
    "#        'id', 'geocode4_corr', 'namepinyin', 'phone'\n",
    "#    ],\n",
    "    #[\n",
    "    #    'namepinyin', 'phone'\n",
    "        #'newID',\n",
    "        #'id'\n",
    "    #],\n",
    "\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df9807 = df_ASIF_city_prov_[~df_ASIF_city_prov_['year'].isin(['2008', '2009'])]\n",
    "#print(df9807.shape)\n",
    "\n",
    "#df_9807  = merge_(list_merge = list_merge,\n",
    "#                  df = df9807,\n",
    "#                  newID = newID,\n",
    "#                  remove_ = True\n",
    "#                 ) \n",
    "#df_9807.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_9807.groupby('size')['size'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#list(df_9807)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_9807[(df_9807['id'] == '102933020') |\n",
    "#         (df_9807['id'] == '102922655')\n",
    "#        ][\n",
    "#    ['year', 'id', 'newID','name', 'citycode', 'output', 'phone', 'id_old', 'id_new']\n",
    "#].sort_values(by = ['newID','year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_9807[(df_9807['newID'] == '5clFOkf2pmm8PZG9l5PvJt6Jd9vRgs')\n",
    "#        ][\n",
    "#    ['year', 'id', 'newID','name', 'citycode', 'output', 'phone', 'id_old', 'id_new']\n",
    "#].sort_values(by = ['newID','year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#(df_9807\n",
    "# .drop_duplicates()\n",
    "# .groupby('newID')\n",
    "# .size()\n",
    "# .sort_values()\n",
    "# .reset_index(name = 'count')\n",
    "# .groupby('count')['newID']\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_9807.loc[lambda x:x['newID'].isin(['9ZX1vcDNgeSNbacGnBoE3Y2CviHAxa'])][\n",
    "#    ['year', 'id', 'newID','name', 'citycode', 'output', 'phone', 'id_old', 'id_new']\n",
    "#].sort_values(by = ['newID','year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_[(df_ASIF_city_prov_['id'] == '120967734') |\n",
    "#         (df_ASIF_city_prov_['id'] == '120966897')\n",
    "#        ][['year', 'id', 'name','output', 'phone', 'geocode4_corr',\n",
    "# 'namepinyin']].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Merge 2008: DEPRECATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#list_merge = [\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'namepinyin',\n",
    "#        'geocode4_corr',\n",
    "#        'phone'],\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'phone',\n",
    "#        'geocode4_corr'],\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'namepinyin'],\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df08 = df_ASIF_city_prov_[df_ASIF_city_prov_['year'].isin(['2008'])]\n",
    "#print(df08.shape)\n",
    "\n",
    "#df_2008  = merge_(list_merge = list_merge,\n",
    "#                  df = df08,\n",
    "#                 remove_ = True) \n",
    "#df_2008.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Merge 2009: DEPRECATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#list_merge = [\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'id',\n",
    "#        'namepinyin',\n",
    "#        'geocode4_corr',\n",
    "#        'phone'\n",
    "#    ],\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'namepinyin',\n",
    "#        'geocode4_corr',\n",
    "#        'phone'],\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'phone',\n",
    "#        'geocode4_corr'],\n",
    "#    [\n",
    "#        'newID',\n",
    "#        'namepinyin'],\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df09 = df_ASIF_city_prov_[df_ASIF_city_prov_['year'].isin(['2009'])]\n",
    "#print(df09.shape)\n",
    "\n",
    "#df_2009  = merge_(list_merge = list_merge,\n",
    "#                  df = df09,\n",
    "#                 remove_ = True ) \n",
    "#df_2009.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## append All and check if correct : DEPRECATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_appended = df_9807.append([df_2008, df_2009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#(df_appended\n",
    "# .drop_duplicates()\n",
    "# .groupby('newID')\n",
    "# .size()\n",
    "# .sort_values()\n",
    "# .reset_index(name = 'count')\n",
    "# .groupby('count')['newID']\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_appended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#pd.concat([\n",
    "#    df_ASIF.groupby('year')['id'].count(),\n",
    "#    df_appended.groupby('year')['newID'].count()\n",
    "#], axis = 1).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_[\n",
    "#        (df_ASIF_city_prov_['id'] == '713996768') \n",
    "#    ][['year', 'id', 'name', 'geocode4_corr', 'output', 'phone']\n",
    "#     ].sort_values(by=['id', 'year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idphone[idphone['id']=='713996768']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idphone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#namephone = (df_ASIF_city_prov_[['name','phone', 'geocode4_corr']]\n",
    "#             .drop_duplicates()\n",
    "#             .rename(columns = {'phone':'dup_phone'})\n",
    "#             .dropna()\n",
    "#            )\n",
    "#namephone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### All name with the phone nimber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#temp = idphone.dropna()\n",
    "#temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idnamephone = temp.merge(namephone,\n",
    "#          on = ['dup_phone','geocode4_corr'],\n",
    "#          how = 'inner').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idnamephone[(idnamephone['id'] == 'HB9432225') |\n",
    "#         (idnamephone['id'] == 'HB9432022')\n",
    "#        ].sort_values(by = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_[\n",
    "#        (df_ASIF_city_prov_['id'] == '156226807') |\n",
    "#        (df_ASIF_city_prov_['id'] == '704886356') |\n",
    "##        (df_ASIF_city_prov_['id'] == '713996768') \n",
    "#    ][['year', 'id', 'name', 'geocode4_corr', 'output', 'phone']\n",
    "#     ].sort_values(by=['id', 'year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idnamephone[(idnamephone['id'] == '156226807') |\n",
    "#            (idnamephone['id'] == '704886356') |\n",
    "#            (idnamephone['id'] == '713996768')\n",
    "#        ].sort_values(by = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idnamephone[(idnamephone['id'] == 'HB9432225') |\n",
    "#         (idnamephone['id'] == 'HB9432022')\n",
    "#        ].sort_values(by = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Unique list of ID and city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idcity = (df_ASIF_city_prov_[['id','geocode4_corr']]\n",
    "##             .drop_duplicates()\n",
    "#            .dropna()\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#idcity.groupby('id')['geocode4_corr'].count().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We create a unique random ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import random \n",
    "#import string\n",
    "#def randomID():\n",
    "##    random_ = ''.join([random.choice(string.ascii_letters+\n",
    "#                                    string.digits) for n in range(30)])\n",
    "#    return random_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#randomID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample = (df_ASIF_city_prov_[['id', 'name', 'geocode4_corr']]\n",
    "#                .drop_duplicates()\n",
    "#                .dropna()\n",
    "#               )\n",
    "\n",
    "#df_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Number of ID with different names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample.groupby('id')['name'].count().reset_index().groupby(by = \"name\").count()\n",
    "#(df_subsample[['id', 'name']]\n",
    "# .drop_duplicates()\n",
    "## .groupby('id')['name']\n",
    "# .count()\n",
    "# .rename('count_ID')\n",
    "# .reset_index()\n",
    "# .groupby('count_ID')\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#(df_subsample[['id', 'geocode4_corr']]\n",
    "# .drop_duplicates()\n",
    "# .groupby('id')['geocode4_corr']\n",
    "# .count()\n",
    "# .rename('count_ID')\n",
    "# .reset_index()\n",
    "# .groupby('count_ID')\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Drop firms with differents cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#multple_cities = (\n",
    "#    df_subsample[['id', 'geocode4_corr']]\n",
    "# .drop_duplicates()\n",
    "# .groupby('id')['geocode4_corr']\n",
    "# .count()\n",
    "# .rename('count_ID')\n",
    "# .reset_index()   \n",
    "# .query('count_ID>1') \n",
    "# .drop(columns = 'count_ID')   \n",
    "#)\n",
    "#multple_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#776931 - 860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample = df_subsample[~df_subsample['id'].isin(multple_cities['id'])]\n",
    "#f_subsample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Merge ID with phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph = df_subsample.merge(idphone,\n",
    "#                   on = ['id', 'geocode4_corr'], \n",
    "#                   how =  'left',\n",
    "#                   indicator=True\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph.groupby('_merge')['_merge'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph = df_subsample_ph.drop(columns = '_merge')\n",
    "#df_subsample_ph[df_subsample_ph['id']=='713996768']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Merge name city code and phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph_name = df_subsample_ph.merge(namephone,\n",
    "#                      on = ['name', 'geocode4_corr', 'dup_phone'],\n",
    "#                      how = 'inner',\n",
    "                      #indicator=True\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph_name.groupby('_merge')['_merge'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_subsample_ph_name[ \n",
    "#    (df_subsample_ph_name['id'] == 'HB9432225') |\n",
    "#    (df_subsample_ph_name['id'] == 'HB9432022')\n",
    "#        ].sort_values(by = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID = (df_subsample\n",
    "#         .groupby('id')\n",
    "#         .apply(lambda x: randomID())\n",
    "#         .rename(\"newID\")\n",
    "#         .reset_index()\n",
    "#         .merge(df_subsample, \n",
    "#                  on = 'id')\n",
    "         #.merge(idnamephone,\n",
    "         #  on = ['geocode4_corr', 'name'])\n",
    "         #.rename(columns = {'dup_phone': 'phone'})\n",
    "         #.merge(idcity, \n",
    "         #       on = ['id']\n",
    "         #      )\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#newID[(newID['id'] == 'HB9432225') |\n",
    "#         (newID['id'] == 'HB9432022')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Merge with name to get a combinaison of ID. For instance, if 1 company name has 2 ID, we had both ID combination\n",
    "\n",
    "Ex:\n",
    "10 A\n",
    "11 A\n",
    "\n",
    "```\n",
    "New frame\n",
    "10 A 10\n",
    "10 A 11\n",
    "11 A 10\n",
    "11 A 11\n",
    "```\n",
    "\n",
    "If we duplicates and keep first, we can assign a single new ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID = (newID\n",
    "#        .merge(\n",
    "#            newID,\n",
    "#            on = ['name', #'phone',\n",
    "#                  'geocode4_corr'],\n",
    "#            suffixes = ['_old', '_new'])\n",
    "#        .drop(columns= ['id_new'])\n",
    "#        .drop_duplicates(\n",
    "#            subset=['newID_old', 'name'],\n",
    "#            keep='first', \n",
    "#            inplace=False)\n",
    "#        .drop(columns= 'newID_old')   \n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Some test\n",
    "\n",
    "Three differences cases:\n",
    "\n",
    "- Wrong ID\n",
    "- Multiple city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID[(df_newID['id_old'] == 'HB9432225') |\n",
    "##         (df_newID['id_old'] == 'HB9432022')\n",
    "       # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID[(df_newID['id_old'] == '62900210X')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "##df_ASIF_city_prov_[\n",
    "#        (df_ASIF_city_prov_['phone'] == '5710786')\n",
    "#    ][['year', 'id', 'name', 'geocode4_corr', 'output', 'phone']\n",
    "#     ].sort_values(by=['id', 'year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID[(df_newID['id_old'] == '156226807') |\n",
    "#         (df_newID['id_old'] == '704886356') |\n",
    "#         (df_newID['id_old'] == '713996768')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "back to our example, when we will merge on one of the three variables above, we end up with the same `ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "##df_ASIF_city_prov_[(df_ASIF_city_prov_['id'] == 'HB9432225') |\n",
    "#        (df_ASIF_city_prov_['id'] == 'HB9432022')\n",
    "#        ][\n",
    "#    ['year', 'id', 'name', 'geocode4_corr', 'output', 'phone']\n",
    "#].sort_values(by = ['id','year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Need to add citycode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Count the number of unqiue firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID['newID_new'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Count the number of firms with many names and many ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#(df_newID\n",
    "# .groupby('newID_new')['id_old']\n",
    "# .count()\n",
    "# .rename('count_ID')\n",
    "# .reset_index()\n",
    "# .groupby('count_ID')\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#(df_newID\n",
    "# .groupby('newID_new')['name']\n",
    "# .count()\n",
    "# .rename('count_ID')\n",
    "# .reset_index()\n",
    "# .groupby('count_ID')\n",
    "# .count()\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Add new ID\n",
    "\n",
    "We can add the new ID by merging on `id_old`. The new consistent ID becomes `newID_new`\n",
    "\n",
    "Note that, for year 2008, we can only merge with `name` since `id` is missing.\n",
    "\n",
    "Year 2009, has also many missing values\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1) Merge using `id`, `name` and `phone`\n",
    "- keep `right_only`\n",
    "\n",
    "2) Merge using `name` and `phone`\n",
    "- Keep `right_only` and delete when `phone == nan`\n",
    "\n",
    "3) Merge using `phone` and `city_code`\n",
    "- Delete left over\n",
    "\n",
    "We take id `HB9432022` and  `HB9432225` as example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID[(df_newID['id_old'] == 'HB9432022') |\n",
    "#         (df_newID['id_old'] == 'HB9432225')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Test\n",
    "\n",
    "Some firms have the same phone numbers but not the same city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_[\n",
    "#        (df_ASIF_city_prov_['id'] == '62900210X')\n",
    "#    ][['year', 'id', 'name', 'geocode4_corr', 'output', 'phone']\n",
    "#     ].sort_values(by=['id', 'year', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_newID[(df_newID['id_old'] == '62900210X')\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_city_prov_[\n",
    "#        (df_ASIF_city_prov_['phone'] == '5710786')\n",
    "#    ][['year', 'id', 'name', 'geocode4_corr', 'output', 'phone']\n",
    "#     ].sort_values(by=['id', 'year', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Year 2004 hasn't been matched but the IDs in 2005 have been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_wave2['example_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_wave2['after_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Archive: Match 2008/2009\n",
    "\n",
    "- Create a dataframe with 2008 and unmatched firms in 2009\n",
    "- Match with name only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#unmatch_2009 = (df_ASIF_new[\n",
    "#    df_ASIF_new['_merge'] == 'right_only']\n",
    "#    .drop(columns = ['id_old',\n",
    "#                     'newID_new',\n",
    "##                     '_merge'\n",
    "#                    ]\n",
    "#                     )\n",
    "#)\n",
    "#df_200809 = (df_ASIF[df_ASIF['year'] == '2008']\n",
    "#           .append(unmatch_2009, sort=False)\n",
    "#           .merge(df_newID,\n",
    "##                 on = 'name',\n",
    "#                 how = 'left',\n",
    "#                 indicator=True\n",
    "#                 )\n",
    "#           .drop(columns= 'id')\n",
    "#          )\n",
    "#df_200809.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_200809.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_200809.groupby(['year', '_merge'])['_merge'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Keep match only and append to `df_ASIF_new``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_200809_both = df_200809[df_200809['_merge'] == 'both']\n",
    "#df_ASIF_new = df_ASIF_new.append(df_200809_both, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#list(df_ASIF_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_new['id_old'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_new['newID_new'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_new = df_ASIF_new.dropna(subset = ['id_old'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Compare before/after matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#pd.concat([\n",
    "#    df_ASIF.groupby('year')['id'].count(),\n",
    "#    df_ASIF_new.groupby('year')['newID_new'].count()\n",
    "#], axis = 1).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Industry name\n",
    "\n",
    "- Create 2 digits industry\n",
    "- Merge industry name\n",
    "\n",
    "We include only manuyfacturing sectors: \n",
    "\n",
    "|  CIC | Industry_Name                                                                      | Short                            |\n",
    "| ---- | ---------------------------------------------------------------------------------- | -------------------------------- |\n",
    "| 13   | Processing of Food from Agricultural Products                                      | Processing foods                 |\n",
    "| 14   | Foods                                                                              | Foods                            |\n",
    "| 15   | Beverages                                                                          | Beverages                        |\n",
    "| 16   | Tobacco                                                                            | Tobacco                          |\n",
    "| 17   | Textile                                                                            | Textile                          |\n",
    "| 18   | Textile Wearing Apparel, Footwear, and Caps                                        | Textile wearing                  |\n",
    "| 19   | Leather, Fur, Feather and Related Products                                         | Leather and others               |\n",
    "| 20   | Processing of Timber, Manufacture of Wood,Bamboo, Rattan, Palm, and Straw Products | Processing of Timber             |\n",
    "| 21   | Furniture                                                                          | Furniture                        |\n",
    "| 22   | Paper and Paper Products                                                           | Paper                            |\n",
    "| 23   | Printing, Reproduction of Recording Media                                          | Printing                         |\n",
    "| 24   | Articles For Culture, Education and Sport Activity                                 |  article                         |\n",
    "| 25   | Processing of Petroleum, Coking, Processing of Nuclear Fuel                        | Processing of Petroleum          |\n",
    "| 26   | Raw Chemical Materials and Chemical Products                                       | Raw Chemical Materials           |\n",
    "| 27   | Medicines                                                                          | Medicines                        |\n",
    "| 28   | Chemical Fibers                                                                    | Chemical Fibers                  |\n",
    "| 29   | Rubber                                                                             | Rubber                           |\n",
    "| 30   | Plastics                                                                           | Plastics                         |\n",
    "| 31   | Non-metallic Mineral Products                                                      | Non-metallic Products            |\n",
    "| 32   | Smelting and Pressing of Ferrous Metals                                            | Smelting ferrous Metals          |\n",
    "| 33   | Smelting and Pressing of Non-ferrous Metals                                        | Smelting Non-ferrous Metals      |\n",
    "| 34   | Metal Products                                                                     | Metals                           |\n",
    "| 35   | General Purpose Machinery                                                          | Machinery                        |\n",
    "| 36   | Special Purpose Machinery                                                          | Special Purpose Machinery        |\n",
    "| 37   | Transport Equipment                                                                | Transport Equipment              |\n",
    "| 39   | Electrical Machinery and Equipment                                                 | Electrical Machine               |\n",
    "| 40   | Communication Equipment, Computers and Other Electronic Equipment                  | Communication Equipment          |\n",
    "| 41   | Measuring Instruments and Machinery for Cultural Activity and Office Work          | Cultural measurement instruments |\n",
    "| 42   | Artwork and Other Manufacturing                                                    | Artwork                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_['indu_2'] = df_ASIF_city_prov_['cic'].str.slice(stop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_indu2 = df_ASIF_city_prov_.merge(df_CIC_industry_name,\n",
    "                       left_on = \"indu_2\",\n",
    "                       right_on = \"CIC\", \n",
    "                       how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_city_prov_indu2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Plot the difference before joining `CIC` and after.\n",
    "\n",
    "- raw -> Raw data\n",
    "- city_merge -> raw data after merged with cities\n",
    "- indu_merge -> city_merge after merged with industry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    df_ASIF.groupby(['year']).size().rename('raw'),\n",
    "    df_ASIF_city_prov_.groupby('year')['id'].count().rename('city_merge'),\n",
    "    df_ASIF_city_prov_indu2.groupby('year')['id'].count().rename('indu_merge')\n",
    "], axis = 1).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Sort variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "to_sort = [\n",
    "    #\"newID\",\n",
    "    \"id\",\n",
    "    \"year\",\n",
    "    \"bdat\",\n",
    "    \"name\",\n",
    "    #'namepinyin',\n",
    "    \"legal_person\",\n",
    "    #\"citycode\",\n",
    "    #'extra_coda',\n",
    "    \"geocode4_corr\",\n",
    "    \"citycn_correct\",\n",
    "    \"cityen_correct\",\n",
    "    \"Province_cn\",\n",
    "    \"Province_en\",\n",
    "    #\"prov2013\",\n",
    "    #\"Provinces\",\n",
    "    \"Lower_location\",\n",
    "    \"Larger_location\",\n",
    "    \"Coastal\",\n",
    "    #'town',\n",
    "    #'village',\n",
    "    #'street',\n",
    "    #'phone',\n",
    "    #'zip',\n",
    "    #'product1_',\n",
    "    \"cic\",\n",
    "    \"indu_2\",\n",
    "    \"CIC\",\n",
    "    \"Industry_Name\",\n",
    "    \"Short\",\n",
    "    \"type\",\n",
    "    \"employment\",\n",
    "    \"output\",\n",
    "    \"revenue\",\n",
    "    \"profit\",\n",
    "    \"wage\",\n",
    "    \"input\",\n",
    "    \"va\",\n",
    "    #'new_product',\n",
    "    \"export\",\n",
    "    \"fa_original\",\n",
    "    \"fa_net\",\n",
    "    \"a_dep\",\n",
    "    \"c_dep\",\n",
    "    'e_state',\n",
    "    'e_collective',\n",
    "    'e_legal_person',\n",
    "    'e_individual',\n",
    "    'e_HMT',\n",
    "    'e_foreign'\n",
    "]\n",
    "df_toclean = df_ASIF_city_prov_indu2[to_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_toclean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_toclean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "2001-2004 does not have value added value. Let's replace them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_toclean.groupby(\"year\")['va'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_tocleanva =  df_toclean.assign(va = lambda x: np.where(\n",
    "    np.logical_or(x['year'] == '2001',\n",
    "                  x['year'] == '2004'),\n",
    "    x['output'] - x['input'],\n",
    "    x['va'])\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_tocleanva.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_tocleanva.groupby(\"year\")['va'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Clean the dataset\n",
    "\n",
    "- According to the profiling, there is issue with the data:\n",
    "\n",
    "- `a_dep` has negative values\n",
    "- `bdat` has year with one digit only\n",
    "- `c_dep` has negative values\n",
    "- Remove `CIC`: same value as `indu_2`\n",
    "- `cic` has `nan`\n",
    "- `export` has negative values\n",
    "- `fa_net` has negative values\n",
    "- `input` has negative values\n",
    "- `ownership` has missing values\n",
    "\n",
    "Most of the variables are highly skew\n",
    "\n",
    "We will proceed as follow:\n",
    "\n",
    "- clean birthdate\n",
    "- Clean negative values\n",
    "- Remove `nan` & `CIC\n",
    "- Clean `ownership`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### Clean birthdate\n",
    "\n",
    "For each `bdat` with digit number inferior to 4, then convert to `nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "count_ = pd.Series(df_tocleanva['bdat'].str.len(), name = 'count_')\n",
    "df_clean = pd.concat([df_tocleanva, count_], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean.groupby('count_')['count_'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['count_'].isin([4])]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#df_final.loc[df_final['count_'] <4] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#df_final['bdat'].str.len().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#df_final = df_final[~df_final['bdat'].isin([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#df_final['bdat'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### Clean negative values\n",
    "\n",
    "Since the variables with negative values are not very compelling, we exclude them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean.describe().style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean_ = df_clean.copy() \n",
    "\n",
    "list_zeroes = ['revenue', 'wage', 'input', 'va',\n",
    "               'fa_original', 'fa_net',\n",
    "               'export',\n",
    "               'a_dep', 'c_dep',\n",
    "               'e_state',\n",
    "               'e_collective',\n",
    "               'e_legal_person',\n",
    "               'e_individual',\n",
    "               'e_HMT',\n",
    "               'e_foreign', 'output', 'employment']\n",
    "\n",
    "for var in list_zeroes:\n",
    "    print(\"Var {0} has {1} values below 1\".format(var,\n",
    "                                                   df_clean_.loc[lambda x : x[var] <= 0][var].count(\n",
    "                                                   )\n",
    "                                                   )\n",
    "          )\n",
    "    if var in ['e_state',\n",
    "               'e_collective',\n",
    "               'e_legal_person',\n",
    "               'e_individual',\n",
    "               'e_HMT',\n",
    "               'e_foreign',\n",
    "               'export',\n",
    "               'a_dep', \n",
    "               'c_dep',\n",
    "              ]:\n",
    "        df_clean_ = df_clean_.loc[lambda x: x[var] >= 0]\n",
    "        \n",
    "    else:\n",
    "        df_clean_ = df_clean_.loc[lambda x: x[var] > 0]\n",
    "df_clean_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean_.describe().style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### CIC\n",
    "\n",
    "Just remove `CIC`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean_ = df_clean_[~df_clean_['cic'].isin([np.nan])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean_['cic'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean_ = df_clean_.drop(columns = ['CIC', 'count_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Clean ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_final = df_final[df_final['ownership'].isin(['Private',\n",
    "#                                     'Collective',\n",
    "#                                     'Foreign',\n",
    "#                                     'HTM',\n",
    "#                                     'SOE'])\n",
    "#        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_final = df_final[\n",
    "#    df_final[\"year\"].isin(\n",
    "#        [\n",
    "#            \"1998\",\n",
    "#            \"1999\",\n",
    "#            \"2000\",\n",
    "#            \"2001\",\n",
    "#            \"2002\",\n",
    "#            \"2003\",\n",
    "#            \"2004\",\n",
    "#            \"2005\",\n",
    "#            \"2006\",\n",
    "#            \"2007\",\n",
    "           #\"2008\",\n",
    "           #\"2009\",\n",
    "#        ]\n",
    "#    )\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_final = df_final.dropna(subset = ['bdat'])\n",
    "#df_final['bdat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_final['year'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Firms share\n",
    "Variables name:\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1gfdmBKzZ1h93atSMFcj_6YgLxC7xX62BCxOngJwf7qE/edit#gid=1504397597\n",
    "\n",
    " use \"type\" variable, classify ownership into four types:\n",
    "- 1=state, \n",
    "- 2=collective, \n",
    "- 3=private, \n",
    "- 4=foreign, \n",
    "- 5=Hong Kong, Macau and Taiwan (4 and 5 can be combined into a single \"foreign\" category\n",
    "  \n",
    "In a nutshell, for the type of firm it is:\n",
    "- 110 141 143 151=1 \n",
    "- 120 130 142 149=2 \n",
    "- 171 172 173 174 190=3 \n",
    "- 210 220 230 240=4 \n",
    "- 310 320 330 340=5\n",
    "\n",
    "```\n",
    "label def\ttype\t110\t\"110 SOE\"\t\n",
    "label def\ttype\t120\t\"120 collective-owned\"\t,add\n",
    "label def\ttype\t130\t\"130 equity JV\"\t,add\n",
    "label def\ttype\t141\t\"141 state coop\"\t,add\n",
    "label def\ttype\t142\t\"142 collective coop\"\t,add\n",
    "label def\ttype\t143\t\"143 state&collective coop\"\t,add\n",
    "label def\ttype\t149\t\"149 other coop\"\t,add\n",
    "label def\ttype\t151\t\"151 SO Ltd liability Co.\"\t,add\n",
    "label def\ttype\t159\t\"159 other Ltd liability Co.\"\t,add\n",
    "label def\ttype\t160\t\"160 Share-holding Co. Ltd\"\t,add\n",
    "label def\ttype\t171\t\"171 private funded\"\t,add\n",
    "label def\ttype\t172\t\"172 private partnership\"\t,add\n",
    "label def\ttype\t173\t\"173 private Ltd liability\"\t,add\n",
    "label def\ttype\t174\t\"174 private Share-holding Co. Ltd\"\t,add\n",
    "label def\ttype\t190\t\"190 other domestic\"\t,add\n",
    "label def\ttype\t210\t\"210 HMT equity JV\"\t,add\n",
    "label def\ttype\t220\t\"220 HMT coop\"\t,add\n",
    "label def\ttype\t230\t\"230 HMT wholly owned\"\t,add\n",
    "label def\ttype\t240\t\"240 HMT Share-holding Co. Ltd\"\t,add\n",
    "label def\ttype\t310\t\"310 foreign equity JV\"\t,add\n",
    "label def\ttype\t320\t\"320 foreign coop\"\t,add\n",
    "label def\ttype\t330\t\"330 foreign wholly owned\"\t,add\n",
    "label def\ttype\t340\t\"340 foreign Share-holding Co. Ltd\"\t,add\n",
    "```\n",
    "\n",
    "The key is \"159\" and \"160\", which are joint stock and stock shareholding. We identify these firms' ownership using the information of other variables about firm equity structure.\n",
    "\n",
    "To include them in either group, firm with the largest equity share.\n",
    "\n",
    "We can't do it in 2008/2009, no equity.\n",
    "\n",
    "*** use \"type\" variable, classify ownership into four types: \n",
    " \n",
    "``` \n",
    "for any HMT collective foreign state individual legal_person: replace e_X=0 if e_X<0\n",
    "egen e_total=rsum(e_*)\n",
    "replace e_state = e_state + e_legal_person\n",
    "for any state collective individual \\ num 1/3: replace ownership=Y if (e_X>=e_state&e_X>=e_collective&e_X>=e_individual)&(ownership==159|ownership==160)\n",
    "tab ownership\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def recode_type(df, recode_type_digit, recode_type_type):\n",
    "    \"\"\"\n",
    "  Recode type:\n",
    "    - 110 141 143 151=1 (State)\n",
    "    - 120 130 142 149=2 (Collective)\n",
    "    - 171 172 173 174 190=3 (Private)\n",
    "    - 210 220 230 240=4 (Foreign)\n",
    "    - 310 320 330 340=5 (HTM)\n",
    "    \n",
    "    Exclude year 2008/2009\n",
    "  \"\"\"\n",
    "    list_drop = [\n",
    "        'e_state', 'e_collective', 'e_legal_person', 'e_individual', 'e_HMT',\n",
    "        'e_foreign'\n",
    "    ]\n",
    "\n",
    "    #for name in list_convert:\n",
    "    #    df[name] = df[name].apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    #df['year'] = df['year'].astype('int')\n",
    "    #df['bdat'] = df['bdat'].apply(\n",
    "    #    pd.to_numeric, errors='coerce').fillna(\n",
    "    #        0, downcast='infer')\n",
    "    \n",
    "    df_exclude0809 = df[~df['year'].isin(['2008', '2009'])]\n",
    "\n",
    "    #dic_q = {'type': recode_type_digit}\n",
    "    df_exclude0809['type_'] = df_exclude0809['type'] \n",
    "    df_asif_recoded = df_exclude0809.replace(recode_type_digit)\n",
    "\n",
    "    #dic_q_ = {'type': recode_type_type}\n",
    "\n",
    "    temp = df_asif_recoded[(df_asif_recoded['type'] == '159') |\n",
    "                           (df_asif_recoded['type'] == '160')]\n",
    "\n",
    "    first_owner = temp.columns.get_loc(\"e_state\")\n",
    "\n",
    "    last_owner = temp.columns.get_loc(\"e_foreign\")\n",
    "    temp = temp.iloc[:, np.r_[first_owner:last_owner]].stack().reset_index()\n",
    "\n",
    "    temp.columns = ['index', 'type', 'capital']\n",
    "    # temp.tail()\n",
    "    temp = temp.set_index('index')\n",
    "    idx = temp.groupby(temp.index)['capital'].transform(max) == temp['capital']\n",
    "    temp = temp[idx]\n",
    "    temp = temp[temp['capital'] != 0]\n",
    "    temp = temp.replace(recode_type_type)\n",
    "\n",
    "    df_recode = df_asif_recoded.copy()\n",
    "\n",
    "    # return df_recode\n",
    "    # The line below is useful if we wnat to slice some ownerships\n",
    "    #df_recode['type'].loc[temp.index] = temp['type']\n",
    "    df_recode = df_recode[~df_recode['type'].isin(['159', '160', '0'])]\n",
    "    df_recode = df_recode.drop(columns=list_drop).rename(columns = {'type_': \n",
    "                                                                    'ownership'})\n",
    "    df_recode['SOE'] = np.where(\n",
    "        df_recode['ownership'] == 'SOE',\n",
    "        'SOE', 'PRIVATE'\n",
    "    )\n",
    "    #df_recode = df_recode.iloc[:,np.r_[0,6, 11:17]]\n",
    "\n",
    "    return df_recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "recode_type_digit = {\n",
    "\n",
    "    'type_': {\n",
    "        '110': 'SOE',\n",
    "        '141': 'SOE',\n",
    "        '143': 'SOE',\n",
    "        '151': 'SOE',\n",
    "        '120': 'Collective',\n",
    "        '130': 'Collective',\n",
    "        '142': 'Collective',\n",
    "        '149': 'Collective',\n",
    "        '171': 'Private',\n",
    "        '172': 'Private',\n",
    "        '173': 'Private',\n",
    "        '174': 'Private',\n",
    "        '190': 'Private',\n",
    "        '210': 'Foreign',\n",
    "        '220': 'Foreign',\n",
    "        '230': 'Foreign',\n",
    "        '240': 'Foreign',\n",
    "        '310': 'HTM',\n",
    "        '320': 'HTM',\n",
    "        '330': 'HTM',\n",
    "        '340': 'HTM'\n",
    "    }\n",
    "}\n",
    "\n",
    "recode_type_ = {\n",
    "    'type_': {\n",
    "        'e_collective': 'Collective',\n",
    "        'e_state': 'SOE',\n",
    "        'e_individual': 'Private',\n",
    "        'e_legal_person': 'Private',\n",
    "        'e_HMT': 'HTM',\n",
    "        'e_foreign': 'Foreign'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "## Ownership 2002-2007\n",
    "\n",
    "We compare with the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_data = df_ASIF.copy()\n",
    "df_ASIF_raw_data = recode_type(\n",
    "    raw_data,\n",
    "    recode_type_digit=recode_type_digit,\n",
    "    recode_type_type=recode_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#raw_data = raw_data.replace(recode_type_digit)[[\n",
    "#    'year', 'id','citycode',\n",
    "#    'output', 'type','e_state', 'e_collective', 'e_legal_person', 'e_individual', 'e_HMT',\n",
    "#        'e_foreign']]\n",
    "#raw_data['SOE'] =np.where(\n",
    "#        raw_data['type'] == 'SOE',\n",
    "#        'SOE', 'PRIVATE'\n",
    "#    )\n",
    "df_ASIF_raw_data.loc[lambda x :x['year'] == '2005'].describe().style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(df_ASIF_raw_data\n",
    " .groupby([ 'year', 'SOE'])['output']\n",
    " .mean()\n",
    " .unstack(-1)\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_1 =  recode_type(\n",
    "    df_clean_,\n",
    "    recode_type_digit=recode_type_digit,\n",
    "    recode_type_type=recode_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Plot the difference before creating `ownership` and after. The blue bars are new dataframe (ie with ownership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    df_ASIF.groupby(['year']).size().rename('raw'),\n",
    "    df_ASIF_city_prov_.groupby('year')['id'].count().rename('city_merge'),\n",
    "    df_ASIF_city_prov_indu2.groupby('year')['id'].count().rename('indu_merge'),\n",
    "    df_ASIF_1.groupby('year')['id'].count().rename('ownership')\n",
    "], axis = 1).plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(df_ASIF_1\n",
    " .groupby([ 'year', 'SOE'])['SOE']\n",
    " .count()\n",
    " .unstack()\n",
    " .plot(kind='bar',stacked=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(df_ASIF_1\n",
    " .groupby([ 'year', 'ownership'])['type']\n",
    " .count()\n",
    " .unstack()\n",
    " .plot(kind='bar',stacked=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(df_ASIF_1\n",
    " .groupby([ 'year'])['output']\n",
    " .describe()\n",
    " .style\n",
    " .format('{0:,.0f}')\n",
    " #.unstack(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    (df_ASIF_raw_data\n",
    "    .groupby(['year'])['output']\n",
    "    .mean()\n",
    "    .rename('mean_raw')\n",
    "    )\n",
    "    ,\n",
    "    (df_ASIF_1\n",
    "     .groupby(['year'])['output']\n",
    "     .mean()\n",
    "     .rename('mean_clean')\n",
    "     )\n",
    "], axis=1\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    (df_ASIF_raw_data\n",
    "    .groupby(['year', 'SOE'])['output']\n",
    "    .mean()\n",
    "    .unstack(-1)\n",
    "    .rename(columns={'PRIVATE': 'PRIVATE_Raw',\n",
    "                     'SOE': \"SOE_Raw\"})\n",
    "    )\n",
    "    ,\n",
    "    (df_ASIF_1\n",
    "     .groupby(['year', 'SOE'])['output']\n",
    "     .mean()\n",
    "     .unstack(-1)\n",
    "     .rename(columns={'PRIVATE': 'PRIVATE_Clean',\n",
    "                     'SOE': \"SOE_Clean\"})\n",
    "     )\n",
    "], axis=1\n",
    ").reindex(columns = ['SOE_Raw', \n",
    "                     'SOE_Clean',\n",
    "                     'PRIVATE_Raw',\n",
    "                     'PRIVATE_Clean']).plot(title = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    (df_ASIF_raw_data\n",
    "    .groupby(['year', 'SOE'])['output']\n",
    "    .median()\n",
    "    .unstack(-1)\n",
    "    .rename(columns={'PRIVATE': 'PRIVATE_Raw',\n",
    "                     'SOE': \"SOE_Raw\"})\n",
    "    )\n",
    "    ,\n",
    "    (df_ASIF_1\n",
    "     .groupby(['year', 'SOE'])['output']\n",
    "     .median()\n",
    "     .unstack(-1)\n",
    "     .rename(columns={'PRIVATE': 'PRIVATE_Clean',\n",
    "                     'SOE': \"SOE_Clean\"})\n",
    "     )\n",
    "], axis=1\n",
    ").reindex(columns = ['SOE_Raw', \n",
    "                     'SOE_Clean',\n",
    "                     'PRIVATE_Raw',\n",
    "                     'PRIVATE_Clean']).plot(title = 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "### Sanitary check \n",
    "\n",
    "``` \n",
    "- 110 141 143 151=1 (State)\n",
    "- 120 130 142 149=2 (Collective)\n",
    "- 171 172 173 174 190=3 (Private)\n",
    "- 210 220 230 240=4 (Foreign)\n",
    "- 310 320 330 340=5 (HTM)\n",
    "```\n",
    "\n",
    "Any issue in the data for type 110? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp = (raw_data\n",
    " .loc[lambda x:\n",
    "      #(x['year'].isin(['2007']))\n",
    "     #& \n",
    "     (x['type'].isin(['110','141','143','151']))]\n",
    " .groupby(['type','year'])['output']\n",
    " .describe()\n",
    " .unstack(0)\n",
    " #.style\n",
    " #.format('{0:,.0f}')\n",
    " )\n",
    "temp[['count', 'mean']].style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "to_slice = ['count', 'mean', 'std', '25%', '50%', '75%', 'max']\n",
    "\n",
    "for x in to_slice:\n",
    "    temp[x].plot(title = x).legend(loc='center left',\n",
    "                                   bbox_to_anchor=(1.25, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(df_ASIF_raw_data\n",
    " .loc[lambda x:x['year'].isin(['2007'])]\n",
    " .groupby(['SOE', 'year'])['output']\n",
    " .describe()\n",
    " .style\n",
    " .format('{0:,.0f}')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(df_ASIF_1\n",
    " .loc[lambda x:x['year'].isin(['2007'])]\n",
    " .groupby(['SOE', 'year'])['output']\n",
    " .describe()\n",
    " .style\n",
    " .format('{0:,.0f}')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_1.groupby('SOE')['output'].describe().style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_1.groupby(['year','SOE'])['output'].mean().unstack(-1).style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_ASIF_1.loc[lambda x:x['SOE'].isin(['SOE'])]['output'],\n",
    "            #rug=True,\n",
    "             hist=False)\n",
    "sns.distplot(df_ASIF_1.loc[lambda x:x['SOE'].isin(['PRIVATE'])]['output'],\n",
    "            #rug=True,\n",
    "             hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "total_id_year = (df_ASIF_1\n",
    " .groupby(['id'])['id']\n",
    " .count()\n",
    " .reset_index(name = 'count')\n",
    " .groupby('count')\n",
    " .count()\n",
    " .assign(total_obs = lambda x:\n",
    "        x.index.get_level_values(0) * x['id'])\n",
    ")\n",
    "total_id_year['id'].plot.bar(title = 'count by # of year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "total_id_year['total_obs'].sum() == df_ASIF_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_ASIF_1.describe().style.format('{0:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Ownership 2008/2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_include0809 = df_appended[df_appended[\"year\"].isin([\"2008\", \"2009\"])]\n",
    "### need to exclude e_*\n",
    "\n",
    "#list_remove = [\n",
    "#    \"e_state\",\n",
    "#   \"e_collective\",\n",
    "#    \"e_legal_person\",\n",
    "#    \"e_individual\",\n",
    "#    \"e_HMT\",\n",
    "#    \"e_foreign\",\n",
    "#]\n",
    "\n",
    "#df_include0809 = df_include0809.drop(columns = list_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#dic_q = {'type': recode_type_digit}\n",
    "#df_0809_ = df_include0809.replace(dic_q)\n",
    "#df_0809_ = df_0809_[~df_0809_['type'].isin(['159', '160', '0'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_0809_['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Append with `df_ASIF_1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_ASIF_1 = df_ASIF_1.append(df_0809_,\n",
    "#                             sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Profiling\n",
    "\n",
    "In order to get a quick summary statistic of the data, we generate an HTML file with the profiling of the dataset we've just created. \n",
    "\n",
    "The profiling will be available at this URL after you commit a push to GitHub. \n",
    "\n",
    "**You need to rename the final dataframe `df_final` in the previous section to generate the profiling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#### make sure the final dataframe is stored as df_final\n",
    "#profile = pandas_profiling.ProfileReport(df_ASIF_1, check_recoded = False)\n",
    "#name_html = \"Dataset_profiling/asif_firm_china.html\"\n",
    "#profile.to_file(output_file=name_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to cloud\n",
    "\n",
    "The dataset is ready to be shared with your colleagues. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "\n",
    "\n",
    "### Move to GCS and BigQuery\n",
    "\n",
    "We move the dataset to the following:\n",
    "\n",
    "- **bucket**: *chinese_data*\n",
    "\n",
    "- **Destination_blob**: *Panel_china/Asif_panel_china/Processed_*\n",
    "- **name**:  *asif_firm_china.gz*\n",
    "- **Dataset**: *China*\n",
    "\n",
    "- **table**: *asif_firm_china*\n",
    "\n",
    "### GCS\n",
    "\n",
    "We first need to save *asif_firm_china* with `.gz` extension locally then we can move it\n",
    "to GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bucket_name = 'chinese_data'\n",
    "destination_blob_name = 'Panel_china/Asif_panel_china/Processed_/asif_firm_china9807Clean.gz'\n",
    "\n",
    "gcp.delete_blob(bucket_name = bucket_name,\n",
    "                destination_blob_name= destination_blob_name)\n",
    "gcp.delete_table(dataset_name = 'China', name_table = 'asif_firm_china9807Clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### First save locally\n",
    "df_ASIF_1.to_csv(\n",
    "\t'asif_firm_china9807Clean.gz',\n",
    "\tsep=',',\n",
    "\theader=True,\n",
    "\tindex=False,\n",
    "\tchunksize=100000,\n",
    "\tcompression='gzip',\n",
    "\tencoding='utf-8')\n",
    "\n",
    "### Then upload to GCS\n",
    "bucket_name = 'chinese_data'\n",
    "destination_blob_name = 'Panel_china/Asif_panel_china/Processed_'\n",
    "source_file_name = 'asif_firm_china9807Clean.gz'\n",
    "gcp.upload_blob(bucket_name, destination_blob_name, source_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "SQL_schema = [\n",
    "    ['newID', 'STRING'],\n",
    "    ['id','STRING'],\n",
    "    ['year','STRING'],\n",
    "    ['bdat','STRING'],\n",
    "    ['name','STRING'],\n",
    "    ['namepinyin','STRING'],\n",
    "    ['legal_person','STRING'],\n",
    "    ['geocode4_corr','STRING'],\n",
    "    ['citycn_correct','STRING'],\n",
    "    ['cityen_correct','STRING'],\n",
    "    ['Province_cn','STRING'],\n",
    "    ['Province_en','STRING'],\n",
    "    ['prov2013','STRING'],\n",
    "    ['Provinces','STRING'],\n",
    "    ['Lower_location','STRING'],\n",
    "    ['Larger_location','STRING'],\n",
    "    ['Coastal','STRING'],\n",
    "    ['cic','STRING'],\n",
    "    ['indu_2','STRING'],\n",
    "    ['Industry_Name','STRING'],\n",
    "    ['Short','STRING'],\n",
    "    ['ownership','STRING'],\n",
    "    ['employment','FLOAT'],\n",
    "    ['output','FLOAT'],\n",
    "    ['revenue','FLOAT'],\n",
    "    ['profit','FLOAT'],\n",
    "    ['wage','FLOAT'],\n",
    "    ['input','FLOAT'],\n",
    "    ['export','FLOAT'],\n",
    "    ['va','FLOAT'],\n",
    "    ['fa_original','FLOAT'],\n",
    "    ['fa_net','FLOAT'],\n",
    "    ['a_dep','FLOAT'],\n",
    "    ['c_dep','FLOAT']\n",
    "]\n",
    "\n",
    "gcp.move_to_bq_autodetect(\n",
    "    dataset_name=\"China\",\n",
    "    name_table=\"asif_firm_china9807Clean\",\n",
    "    bucket_gcs=\"chinese_data/Panel_china/Asif_panel_china/Processed_/asif_firm_china9807Clean.gz\",\n",
    "    #sql_schema=SQL_schema,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "list_gz = glob.glob('asif_year_*.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "[os.remove(item) for item in list_gz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.remove('asif_firm_china9807Clean.csv')\n",
    "os.remove('asif_firm_china9807Clean.gz')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
