{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Table 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "from Fast_connectCloud import connector\n",
    "from GoogleDrivePy.google_drive import connect_drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gs = connector.open_connection(online_connection = False,\n",
    "                              path_credential = \n",
    "                               '/Users/thomas/Google Drive/Projects/Client_Oauth/Google_auth/'\n",
    "                              )\n",
    "service_gd = gs.connect_remote(engine = 'GS')\n",
    "gdr = connect_drive.connect_drive(service_gd['GoogleDrive'])\n",
    "service = gs.connect_remote('GCP')\n",
    "from GoogleDrivePy.google_platform import connect_cloud_platform\n",
    "project = 'valid-pagoda-132423'\n",
    "gcp = connect_cloud_platform.connect_console(project = project, \n",
    "                                             service_account = service['GoogleCloudP'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "aggregation_param = 'geocode4_corr'\n",
    "decile = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## Load cityname_and_code from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA\n",
    "### To change the range\n",
    "\n",
    "sheetid = '1fIziz-Xt99-Rj6NLm52-i6jScOLXgAY20KJi8k3DruA'\n",
    "sheetname = 'final'\n",
    "\n",
    "df_cityname_and_code = gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_cityname_and_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## Load TCZ_list_china from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/15bMeS2cMfGfYJkjuY6wOMzcAUWZNRGpO03hZ8rpgv0Q\n",
    "### To change the range\n",
    "\n",
    "sheetid = '15bMeS2cMfGfYJkjuY6wOMzcAUWZNRGpO03hZ8rpgv0Q'\n",
    "sheetname = 'TCZ'\n",
    "\n",
    "df_TCZ_list_china = gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True)\n",
    "df_TCZ_list_china.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Load yearbook9813 from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset\n",
    "\n",
    "We need this table for the table 0 -> Need year 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "### Please go here https://docs.google.com/spreadsheets/d/15bMeS2cMfGfYJkjuY6wOMzcAUWZNRGpO03hZ8rpgv0Q\n",
    "### To change the range\n",
    "\n",
    "\n",
    "sheetid = '1NpfDQ6dz7knjZDPSjRz2QanVf7td3ujSQn7hD7Gxkow'\n",
    "sheetname = 'yearbook'\n",
    "\n",
    "yearbook9813 = (gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True).loc[lambda x: x['year'].isin(['2003','2004',\n",
    "                                                       '2005', '2006',\n",
    "                                                       '2007', '2008',\n",
    "                                                       '2009', '2010'])]\n",
    "                .drop(columns = ['代码',\n",
    "                  '简称', \n",
    "                  \"[Envirct06:工业二氧化硫去除量][单位:吨]\",\n",
    "                 '[Envirct08:工业烟尘去除量][单位:吨]',\n",
    "                 '[Envirct09:工业烟尘排放量][单位:吨]']\n",
    "               )\n",
    "                .rename(columns = {'[Envirct07:工业二氧化硫排放量][单位:吨]':\n",
    "                                   'tso2'})\n",
    "                .assign(tso2 = lambda x: pd.to_numeric(x['tso2'],\n",
    "                                                         errors = 'coerce'\n",
    "                                                         )\n",
    "                                                         )\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load chinese_city_characteristics from Google Spreadsheet\n",
    "\n",
    "Feel free to add description about the dataset or any usefull information.\n",
    "\n",
    "Profiling will be available soon for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chinese_city_characteristics = pd.read_csv('../df_chinese_city_characteristics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## Paper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "query = (\n",
    "          \"SELECT * \"\n",
    "            \"FROM China.SBC_pollution_China \"\n",
    "\n",
    "        )\n",
    "\n",
    "df_final = gcp.upload_data_from_bigquery(query = query, location = 'US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "list_agg = df_final[aggregation_param].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## Pollution China 1998-2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "query = (\"\"\"SELECT SUM( tso2) sum_so2, year, citycode as geocode4_corr\n",
    "FROM China.pollution_city_cic4_china\n",
    "GROUP BY year, citycode\n",
    "\"\"\"\n",
    "        )\n",
    "df_pol = (gcp.upload_data_from_bigquery(query = query, location = 'US')\n",
    "          .loc[lambda x: ~x['geocode4_corr'].isna()]\n",
    "      .assign(geocode4_corr = lambda x: \n",
    "              x['geocode4_corr'].astype(int).astype('str')\n",
    "             )\n",
    "         )\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "### Zhaoruili data\n",
    "sheetid = '1kSyGnkWOwoGVe1PgsQUGoWYO3DB8p9fgVh_VE6ilBt8'\n",
    "sheetname = 'SO2_emission'\n",
    "\n",
    "df_TCZ_SO2_Zhaoruili= gdr.upload_data_from_spreadsheet(sheetID = sheetid,\n",
    "sheetName = sheetname,\n",
    "\t to_dataframe = True).apply(lambda x: pd.to_numeric(x, errors ='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## Compute Herfhindal: proxy Size\n",
    "\n",
    "$$\n",
    "H=\\sum_{i=1}^{N} s_{i}^{2}\n",
    "$$\n",
    "\n",
    "where $s_i$ is the market share of industry[city] $i$ in a city [industry], and $N$ is the number of firms. \n",
    "\n",
    "We proceed as follow:\n",
    "- Step 1: Compute the share [output, capital, employment] by city-industry: `market_share_cit`\n",
    "- Step 2: compute the sum of squared market share by industry[city]: `Herfindahl_agg_t`\n",
    "- Step 3: Compute the average across time: `Herfindahl_agg`\n",
    "- Step 4: Compute the deciles of step 3: `decile_herfhindal_agg`\n",
    "    - Low decile implies a low concentration within sectors\n",
    "    - High decile implies a high concentration within sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH sum_cit AS (\n",
    "  SELECT geocode4_corr, cic as industry, sum(output) as sum_o_cit, year\n",
    "  FROM China.asif_firm_china \n",
    "  WHERE year >= 2002 AND year <= 2007\n",
    "  AND output > 0 \n",
    "    AND fa_net > 0 \n",
    "    AND employment > 0 \n",
    "  GROUP BY geocode4_corr, cic, year\n",
    ") \n",
    "SELECT * \n",
    "FROM \n",
    "  (WITH sum_agg_t AS (\n",
    "    SELECT {0}, SUM(sum_o_cit) as sum_o_agg_t, year\n",
    "    FROM sum_cit\n",
    "    WHERE year >= 2002 AND year <= 2007\n",
    "    GROUP BY year, {0}\n",
    ")\n",
    "SELECT *\n",
    "FROM\n",
    "  (WITH ms_cit AS (\n",
    "    SELECT  sum_cit.industry, sum_cit.geocode4_corr, sum_cit.year,\n",
    "    sum_cit.sum_o_cit/NULLIF(sum_agg_t.sum_o_agg_t, 0) as market_share_cit\n",
    "    FROM sum_cit\n",
    "    LEFT JOIN sum_agg_t\n",
    "ON (\n",
    "sum_cit.year = sum_agg_t.year AND \n",
    "sum_cit.{0} = sum_agg_t.{0}\n",
    ")\n",
    ")\n",
    "SELECT *\n",
    "FROM\n",
    "  (WITH agg_1 AS (\n",
    "SELECT {0}, SUM(POW(market_share_cit, 2)) as Herfindahl_agg_t,\n",
    "year\n",
    "FROM ms_cit\n",
    "GROUP BY year, {0}\n",
    "ORDER BY year, {0} \n",
    ")\n",
    "SELECT *\n",
    "FROM (\n",
    "SELECT {0},\n",
    "AVG(Herfindahl_agg_t) as Herfindahl_agg\n",
    "FROM agg_1\n",
    "GROUP BY {0}\n",
    "ORDER BY {0}\n",
    ")\n",
    "\n",
    ")))\n",
    "\"\"\"\n",
    "df_herfhindal = (gcp.upload_data_from_bigquery(\n",
    "    query = query.format(aggregation_param),\n",
    "                                         location = 'US')\n",
    "                 .loc[lambda x: x[aggregation_param].isin(list_agg)]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "df_herfhindal_final = (df_final.merge(df_herfhindal,\n",
    "                                     on=[aggregation_param],\n",
    "                                     how='left',\n",
    "                                     indicator=True\n",
    "                                     )\n",
    "                       .assign(\n",
    "                       decile_herfhindal = lambda x:\n",
    "                           pd.qcut(x['Herfindahl_agg'],10, labels=False),\n",
    "                       mean_herfhindal= \n",
    "                           lambda x: np.where(\n",
    "                               x[\"Herfindahl_agg\"] > \n",
    "                               x[\"Herfindahl_agg\"].drop_duplicates().mean(),\n",
    "                               1,0\n",
    "                           ),\n",
    "                       third_herfhindal= \n",
    "                           lambda x: np.where(\n",
    "                               x[\"Herfindahl_agg\"] >\n",
    "                               (x[\"Herfindahl_agg\"]\n",
    "                                .drop_duplicates()\n",
    "                                .quantile([.75])\n",
    "                                .values[0]),\n",
    "                               1,0\n",
    "                           ),\n",
    "                    concentrated_city = lambda x:np.where(\n",
    "                    x['decile_herfhindal'] > decile,\n",
    "                           'Concentrated city',\"No Concentrated city\"\n",
    "                    )\n",
    "                       )[['geocode4_corr',\n",
    "                                           'concentrated_city']].drop_duplicates(\n",
    "    subset = 'geocode4_corr')\n",
    "                .assign(geocode4_corr = lambda x: \n",
    "                        x['geocode4_corr'].astype('str'))\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## SOE vs Private\n",
    "\n",
    "We proceed as follow:\n",
    "- Step 1: Compute the share [output, capital, employment] by industry[city], ownership (SOE/PRIVATE): `Share_X_agg_o`\n",
    "- ~Step 2: Compute dummy when share SOE above share domestic by industry[city]~\n",
    "- Step 3: Compute decile by industry[city]-ownership\n",
    "    - Note,  high decile in SOE means the industry[city] has relatively high share of SOE output, but not in absolule value as in step 2. A decile 9 in SOE can be a decile 2 or 3 in Domestic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "query_share_ = \"\"\" \n",
    "WITH sum_agg_o AS (\n",
    "  SELECT \n",
    "    case WHEN ownership = '{2}' THEN '{2}' ELSE '{3}' END AS OWNERSHIP, \n",
    "    SUM(output / 10000000) as output_agg_o, \n",
    "    SUM(fa_net / 10000000) as fa_net_agg_o, \n",
    "    SUM(employment / 100000) as employment_agg_o,\n",
    "    {1} as {0}\n",
    "  FROM \n",
    "    China.asif_firm_china \n",
    "  WHERE \n",
    "    year >= 2002 \n",
    "    AND year <= 2007 \n",
    "    AND output > 0 \n",
    "    AND fa_net > 0 \n",
    "    AND employment > 0 \n",
    "  GROUP BY \n",
    "    OWNERSHIP, \n",
    "    {0}\n",
    ") \n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  (\n",
    "    WITH sum_agg AS(\n",
    "      SELECT \n",
    "        SUM(output_agg_o) as output_agg, \n",
    "        SUM(fa_net_agg_o) as fa_net_agg, \n",
    "        SUM(employment_agg_o) as employment_agg, \n",
    "        {0} AS {0}_b\n",
    "      FROM \n",
    "        sum_agg_o \n",
    "      GROUP BY \n",
    "        {0}\n",
    "    ) \n",
    "    SELECT \n",
    "      * \n",
    "    FROM \n",
    "      (\n",
    "        WITH share_agg_o AS(\n",
    "          SELECT \n",
    "            OWNERSHIP, \n",
    "            output_agg_o / output_agg AS share_output_agg_o, \n",
    "            fa_net_agg_o / fa_net_agg AS share_fa_net_agg_o, \n",
    "            employment_agg_o / employment_agg AS share_employement_agg_o, \n",
    "            {0}\n",
    "          FROM \n",
    "            sum_agg_o \n",
    "            LEFT JOIN sum_agg ON sum_agg_o.{0} = sum_agg.{0}_b \n",
    "        ) \n",
    "        SELECT \n",
    "        {0},\n",
    "        OWNERSHIP,  \n",
    "        share_output_agg_o,\n",
    "        share_fa_net_agg_o,\n",
    "        share_employement_agg_o\n",
    "        FROM share_agg_o\n",
    "        WHERE OWNERSHIP = '{2}'\n",
    "        )\n",
    "        )\n",
    "\"\"\"\n",
    "OWNERSHIP = 'SOE'\n",
    "counterpart = 'PRIVATE'\n",
    "\n",
    "df_share_soe= query_share_.format(aggregation_param,\n",
    "                                             aggregation_param,\n",
    "                                             OWNERSHIP,\n",
    "                                            counterpart)\n",
    "    \n",
    "df_share_soe = (gcp.upload_data_from_bigquery(query = df_share_soe,\n",
    "                                         location = 'US')\n",
    "                    .loc[lambda x: x[aggregation_param].isin(list_agg)]\n",
    "                   )\n",
    "df_share_soe.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "# Table 1\n",
    "\n",
    "Ouput: \n",
    "\n",
    "- Overleaf\n",
    "    - Temp_tables/Tables_paper/02_paper_version_2/11_table_stat\n",
    "- Google Drive\n",
    "    - [11_table_stat](https://drive.google.com/open?id=1Xejq3Jem9sD34yif7s_8Co-4bAP4wWe9)\n",
    "![](https://drive.google.com/uc?export=view&id=1Xejq3Jem9sD34yif7s_8Co-4bAP4wWe9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "#### If industry, we need to use out_share_SOE, cap_share_SOE,lab_share_SOE\n",
    "##### Output share already computed in the paper's table for industry but not\n",
    "##### for city, in the later case, we use the data from ASIF\n",
    "decile =6\n",
    "\n",
    "if aggregation_param== 'industry':\n",
    "    out = \"out_share_SOE\"\n",
    "    cap = \"cap_share_SOE\"\n",
    "    emp = \"lab_share_SOE\"\n",
    "else:\n",
    "    out = \"share_output_agg_o\"\n",
    "    cap = \"share_fa_net_agg_o\"\n",
    "    emp = \"share_employement_agg_o\"\n",
    "    \n",
    "df_final_SOE = (df_final.merge(\n",
    "    df_share_soe,\n",
    "    on = [aggregation_param],\n",
    "    how = 'left',\n",
    "    indicator = True\n",
    ")\n",
    "                .assign(\n",
    "                       output = lambda x:\n",
    "                           pd.qcut(x[out],10, labels=False),\n",
    "                       capital = lambda x:\n",
    "                           pd.qcut(x[cap],10, labels=False),\n",
    "                       employment = lambda x:\n",
    "                           pd.qcut(x[emp],10, labels=False),\n",
    "                       mean_output = lambda x:np.where(\n",
    "                    x[out] > x[out].drop_duplicates().mean(),\n",
    "                           1,0\n",
    "                       ),\n",
    "                    mean_capital = lambda x:np.where(\n",
    "                    x[cap] > x[cap].drop_duplicates().mean(),\n",
    "                           1,0\n",
    "                       ),\n",
    "                    mean_employment = lambda x:np.where(\n",
    "                    x[emp] > x[emp].drop_duplicates().mean(),\n",
    "                           1,0\n",
    "                       ),\n",
    "                    soe_city = lambda x:np.where(\n",
    "                    x['output'] > decile,\n",
    "                           'SOE dominated',\"No SOE dominated\"\n",
    "                       )\n",
    "                    \n",
    "                    )\n",
    "                .drop(columns = '_merge')[['geocode4_corr',\n",
    "                                           'output',\n",
    "                                           'TCZ_c',\n",
    "                                          'soe_city',\n",
    "                                          'target_c']].drop_duplicates(\n",
    "    subset = 'geocode4_corr')\n",
    "            .assign(geocode4_corr = lambda x: \n",
    "                        x['geocode4_corr'].astype('str'))\n",
    "                \n",
    "\n",
    ")\n",
    "df_final_SOE['soe_city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "df_final_SOE_table2 = (df_final.merge(\n",
    "    df_share_soe,\n",
    "    on = [aggregation_param],\n",
    "    how = 'left',\n",
    "    indicator = True\n",
    ")\n",
    "                .assign(\n",
    "                       output = lambda x:\n",
    "                           pd.qcut(x[out],10, labels=False),\n",
    "                       capital = lambda x:\n",
    "                           pd.qcut(x[cap],10, labels=False),\n",
    "                       employment = lambda x:\n",
    "                           pd.qcut(x[emp],10, labels=False),\n",
    "                       mean_output = lambda x:np.where(\n",
    "                    x[out] > x[out].drop_duplicates().mean(),\n",
    "                           1,0\n",
    "                       ),\n",
    "                    mean_capital = lambda x:np.where(\n",
    "                    x[cap] > x[cap].drop_duplicates().mean(),\n",
    "                           1,0\n",
    "                       ),\n",
    "                    mean_employment = lambda x:np.where(\n",
    "                    x[emp] > x[emp].drop_duplicates().mean(),\n",
    "                           1,0\n",
    "                       ),\n",
    "                    soe_city = lambda x:np.where(\n",
    "                    x['output'] > decile,\n",
    "                           'SOE dominated',\"No SOE dominated\"\n",
    "                    )\n",
    "                )[['geocode4_corr',\n",
    "                   'soe_city',\n",
    "                   'Lower_location',\n",
    "                   'Larger_location',\n",
    "                   'TCZ_c',\n",
    "                   'Coastal',\n",
    "     'share_output_agg_o',\n",
    "     'share_fa_net_agg_o',\n",
    "     'share_employement_agg_o',\n",
    "                  'target_c']]\n",
    "                       .drop_duplicates(subset = 'geocode4_corr')\n",
    "                       .assign(geocode4_corr = lambda x: \n",
    "                        x['geocode4_corr'].astype('str'))\n",
    "                      )\n",
    "df_final_SOE_table2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "### 1998-2000\n",
    "\n",
    "- TCZ\n",
    "- No TCZ\n",
    "- SOE\n",
    "- No SOE\n",
    "- Full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "dic_ = {\n",
    "    '1998-2001': [],\n",
    "    '2002-2005': [],\n",
    "    '2006-2010': [],\n",
    "    'Target':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t1 = (df_TCZ_SO2_Zhaoruili\n",
    " .loc[lambda x: (~x['tcz'].isin(['OTHER']))\n",
    "     & (x['year'].isin(['1998', '2000'#, '2001', '2005'\n",
    "                       ]))]\n",
    " .set_index(['tcz', 'year'])\n",
    " .groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "\n",
    "dic_['1998-2001'].append(np.round(t1.loc['No_TCZ'].values[0][0], 2))\n",
    "dic_['1998-2001'].append(np.round(t1.loc['TCZ'].values[0][0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t2 = (df_pol\n",
    " .merge(df_final_SOE, \n",
    "        how = 'right'\n",
    "       )\n",
    " .assign(sum_so2 = lambda x: x['sum_so2'].fillna(0))\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['1998', '2001']))\n",
    "     ]\n",
    "  .groupby(['soe_city',\"year\"])['sum_so2']\n",
    " .sum()\n",
    " .groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "dic_['1998-2001'].append(np.round(t2.loc['No SOE dominated'].values[0], 2))\n",
    "dic_['1998-2001'].append(np.round(t2.loc['SOE dominated'].values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t3 = (df_TCZ_SO2_Zhaoruili\n",
    " .loc[lambda x: (~x['tcz'].isin(['OTHER']))\n",
    "     & (x['year'].isin(['1998', '2000'#, '2001', '2005'\n",
    "                       ]))]\n",
    " .set_index(['tcz', 'year'])\n",
    " .groupby(level = 1)\n",
    " .sum()\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "dic_['1998-2001'].append(np.round(t3.loc[2000].values[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "### 2001-2005\n",
    "\n",
    "- TCZ\n",
    "- No TCZ\n",
    "- SOE\n",
    "- No SOE\n",
    "- Full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t1 = (df_TCZ_SO2_Zhaoruili\n",
    " .loc[lambda x: (~x['tcz'].isin(['OTHER']))\n",
    "     & (x['year'].isin(['2001', '2005'#, '2001', '2005'\n",
    "                       ]))]\n",
    " .set_index(['tcz', 'year'])\n",
    " .groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "dic_['2002-2005'].append(np.round(t1.loc['No_TCZ'].values[0][0], 2))\n",
    "dic_['2002-2005'].append(np.round(t1.loc['TCZ'].values[0][0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t2 = (df_pol\n",
    " .merge(df_final_SOE, \n",
    "        how = 'right'\n",
    "       )\n",
    " .assign(sum_so2 = lambda x: x['sum_so2'].fillna(0))\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['2001', '2005']))\n",
    "     ]\n",
    "  .groupby(['soe_city',\"year\"])['sum_so2']\n",
    " .sum()\n",
    " .groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "dic_['2002-2005'].append(np.round(t2.loc['No SOE dominated'].values[0], 2))\n",
    "dic_['2002-2005'].append(np.round(t2.loc['SOE dominated'].values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t3 = (df_TCZ_SO2_Zhaoruili\n",
    " .loc[lambda x: (~x['tcz'].isin(['OTHER']))\n",
    "     & (x['year'].isin(['2001', '2005'#, '2001', '2005'\n",
    "                       ]))]\n",
    " .set_index(['tcz', 'year'])\n",
    " .groupby(level = 1)\n",
    " .sum()\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "dic_['2002-2005'].append(np.round(t3.loc[2005].values[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "### 2006-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t1 = (df_cityname_and_code\n",
    " .drop(\n",
    "    columns=['citycn',\n",
    "             'cityen',\n",
    "             'citycn_correct',\n",
    "             'cityen_correct',\n",
    "             'Province_cn',\n",
    "             'Province_en'])\n",
    " .merge(yearbook9813.rename(columns = {'geocode4_corr' : 'extra_coda'}))\n",
    " .drop(columns = ['extra_coda'])\n",
    " .merge(df_TCZ_list_china[['geocode4_corr', 'TCZ']], how = \"left\")\n",
    " .merge(df_final_SOE, on = ['geocode4_corr'],how = 'left')\n",
    " .apply(lambda x: pd.to_numeric(x, errors = 'coerce'))\n",
    " .assign(TCZ = lambda x: x['TCZ'].fillna(0))\n",
    " .replace({'TCZ': {0: 'No_TCZ', 1:'TCZ'}})\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['2006', '2010']))]\n",
    "  .groupby(['TCZ',\"year\"])['tso2']\n",
    " .sum()\n",
    " .groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "\n",
    "dic_['2006-2010'].append(np.round(t1.loc['No_TCZ'].values[0], 2))\n",
    "dic_['2006-2010'].append(np.round(t1.loc['TCZ'].values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "#### average target\n",
    "t1 = (df_cityname_and_code\n",
    " .drop(\n",
    "    columns=['citycn',\n",
    "             'cityen',\n",
    "             'citycn_correct',\n",
    "             'cityen_correct',\n",
    "             'Province_cn',\n",
    "             'Province_en'])\n",
    " .merge(yearbook9813.rename(columns = {'geocode4_corr' : 'extra_coda'}))\n",
    " .drop(columns = ['extra_coda'])\n",
    " .merge(df_TCZ_list_china[['geocode4_corr', 'TCZ']], how = \"left\")\n",
    " .merge(df_final_SOE, on = ['geocode4_corr'],how = 'left')\n",
    " .apply(lambda x: pd.to_numeric(x, errors = 'coerce'))\n",
    " .assign(TCZ = lambda x: x['TCZ'].fillna(0))\n",
    " .replace({'TCZ': {0: 'No_TCZ', 1:'TCZ'}})\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['2006']))]\n",
    "  .groupby(['TCZ',\"year\"])['target_c']\n",
    ".mean()\n",
    "     )\n",
    "dic_['Target'].append(-np.round(t1.loc['No_TCZ'].values[0], 2))\n",
    "dic_['Target'].append(-np.round(t1.loc['TCZ'].values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t2 = (yearbook9813\n",
    " .merge(df_final_SOE, \n",
    "        how = 'right'\n",
    "       )\n",
    " .assign(sum_so2 = lambda x: x['tso2'].fillna(0))\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['2006', '2010']))\n",
    "     ]\n",
    "  .groupby(['soe_city',\"year\"])['tso2']\n",
    " .sum()\n",
    " .groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "\n",
    "dic_['2006-2010'].append(np.round(t2.loc['No SOE dominated'].values[0], 2))\n",
    "dic_['2006-2010'].append(np.round(t2.loc['SOE dominated'].values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "### target\n",
    "t2 = (yearbook9813\n",
    " .merge(df_final_SOE, \n",
    "        how = 'right'\n",
    "       )\n",
    " .assign(sum_so2 = lambda x: x['tso2'].fillna(0))\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['2006']))\n",
    "     ]\n",
    "  .groupby(['soe_city',\"year\"])['target_c']\n",
    "  .mean()\n",
    "     )\n",
    "dic_['Target'].append(-np.round(t2.loc['No SOE dominated'].values[0], 2))\n",
    "dic_['Target'].append(-np.round(t2.loc['SOE dominated'].values[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t3 = (df_cityname_and_code\n",
    " .drop(\n",
    "    columns=['citycn',\n",
    "             'cityen',\n",
    "             'citycn_correct',\n",
    "             'cityen_correct',\n",
    "             'Province_cn',\n",
    "             'Province_en'])\n",
    " .merge(yearbook9813.rename(columns = {'geocode4_corr' : 'extra_coda'}))\n",
    " .drop(columns = ['extra_coda'])\n",
    " .merge(df_TCZ_list_china[['geocode4_corr', 'TCZ']], how = \"left\")\n",
    " .merge(df_final_SOE, on = ['geocode4_corr'],how = 'left')\n",
    " .apply(lambda x: pd.to_numeric(x, errors = 'coerce'))\n",
    " .assign(TCZ = lambda x: x['TCZ'].fillna(0))\n",
    " .replace({'TCZ': {0: 'No_TCZ', 1:'TCZ'}})\n",
    " .loc[lambda x: \n",
    " (x['year'].isin(['2006', '2010']))]\n",
    "  .groupby([\"year\"])['tso2']\n",
    " .sum()\n",
    " #.groupby(level = 0)\n",
    " .pct_change()\n",
    " .dropna()\n",
    ")\n",
    "dic_['2006-2010'].append(np.round(t3.loc[2010], 2))\n",
    "dic_['Target'].append(-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "for i in range(1, 19):\n",
    "    try:\n",
    "        os.remove(\"table_{}.pdf\".format(i))\n",
    "        os.remove(\"table_{}.tex\".format(i))\n",
    "        os.remove(\"table_{}.txt\".format(i))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "title = \"SO2 reduction during the subsequent FYPs\"\n",
    "(pd.DataFrame(dic_, index= ['No TCZ','TCZ',\n",
    "                           'No Dominated SOE^a',\n",
    "                           ' Dominated SOE^a',\n",
    "                           'Full Sample'])\n",
    " .rename_axis('Cities')\n",
    " .reset_index()\n",
    " .to_latex('table_1.tex',\n",
    "           caption = title,\n",
    "           index=False,\n",
    "           label = \"table_1\",\n",
    "           float_format=\"{:,.2%}\".format)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "import sys, os, shutil\n",
    "sys.path.insert(0,'..')\n",
    "import functions.latex_beautify as lb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "jupyter_preview = False\n",
    "table_nte = \"\"\"\n",
    "Sources: Author's own computation  \\n\n",
    "The list of TCZ is provided by the State Council, 1998.\n",
    "\"Official Reply to the State Council Concerning Acid Rain Control Areas\n",
    "and Sulfur Dioxide Pollution Control Areas\".\n",
    "The information about the SO2 level are collected using various edition\n",
    "of the China Environment Statistics Yearbook.\n",
    "We compute the reduction of SO2 emission using the same methodology\n",
    "as Chen and al.(2018).  \\n\n",
    "$a$ (No) Dominated SOEs cities refer to cities where the \n",
    "(output, capital, employment) share of SOEs is (below) above a critical threshold,\n",
    "for instance the 6th decile\n",
    "\"\"\"\n",
    "lb.beautify_table(table_nte = table_nte,\n",
    "                  name = 'table_1',\n",
    "                  jupyter_preview  = jupyter_preview,\n",
    "                  resolution = 500)\n",
    "if jupyter_preview == False:\n",
    "    source_to_move = ['table_1.tex']\n",
    "    dest = ['Overleaf_statistic/11_table_stat.tex'\n",
    "           ]\n",
    "    for i, v in enumerate(source_to_move):\n",
    "        shutil.move(\n",
    "            v,\n",
    "            dest[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "# Table 2\n",
    "\n",
    "Ouput: \n",
    "\n",
    "- Overleaf\n",
    "    - Temp_tables/Tables_paper/02_paper_version_2/11_table_stat\n",
    "- Google Drive\n",
    "    - [11_table_stat](https://drive.google.com/open?id=1MdWuHFzX-Ow5M34T8GnGiKQvFpmXY9I7)\n",
    "![](https://drive.google.com/uc?export=view&id=1MdWuHFzX-Ow5M34T8GnGiKQvFpmXY9I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t0 = (df_final_SOE_table2[['share_output_agg_o', 'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .set_index('index')\n",
    "      .T\n",
    "      .rename(index={0: 'Full sample'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t1 = df_final_SOE_table2.groupby('Lower_location')[['share_output_agg_o',\n",
    "                                                    'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t2 = df_final_SOE_table2.groupby('Larger_location')[['share_output_agg_o',\n",
    "                                                     'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t3 = df_final_SOE_table2.groupby('TCZ_c')[['share_output_agg_o',\n",
    "                                           'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']].mean().rename(index={'No_TCZ': 'No TCZ'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "t4 = (df_final_SOE_table2\n",
    " .merge(df_herfhindal_final)\n",
    " .groupby('concentrated_city')[['share_output_agg_o', 'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']]\n",
    " .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "jupyter_preview = False\n",
    "for i in range(1, 19):\n",
    "    try:\n",
    "        os.remove(\"table_{}.pdf\".format(i))\n",
    "        os.remove(\"table_{}.tex\".format(i))\n",
    "        os.remove(\"table_{}.txt\".format(i))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "title = \"Summary statistics by city characteristics\"\n",
    "header = [\"Output share SOE_i\", \"Capital share SOE_i\",\"Employment share SOE_i\"\n",
    "          #, \"Target_i\"\n",
    "         ]\n",
    "#pd.concat([\n",
    "#   pd.concat([t0, t1, t2, t3, t4], axis = 0),\n",
    "#    pd.concat([t5, t6, t7, t8, t9], axis = 0)\n",
    "#], axis = 1)\n",
    "pd.concat([t0, t1, t2, t3, t4], axis = 0).to_latex(\n",
    "    'table_1.tex',\n",
    "    caption = title,\n",
    "    index=True,\n",
    "    label = \"table_1\",\n",
    "    header = header,\n",
    "    float_format=\"{:,.2%}\".format)\n",
    "\n",
    "table_nte = \"\"\"\n",
    "Sources: Author's own computation \\n\n",
    "The list of TCZ is provided by the State Council, 1998. \\n\n",
    "Output $\\text { Share SOE }_{i}$ refers to the ratio of output\n",
    "(respectively capital, employment) of SOEs over the total production\n",
    "(capital, employment) in city $i$\n",
    "      \n",
    "\"\"\"\n",
    "lb.beautify_table(table_nte = table_nte,\n",
    "                  name = 'table_1',\n",
    "                  jupyter_preview  = jupyter_preview,\n",
    "                  resolution = 200)\n",
    "\n",
    "if jupyter_preview == False:\n",
    "    source_to_move = ['table_1.tex']\n",
    "    dest = ['Overleaf_statistic/12_table_stat.tex'\n",
    "           ]\n",
    "    for i, v in enumerate(source_to_move):\n",
    "        shutil.move(\n",
    "            v,\n",
    "            dest[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for the text:\n",
    "\n",
    "SOE share by:\n",
    "\n",
    "- Hinterland\n",
    "- SPZ/no SPZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([(df_final_SOE_table2\n",
    " .merge(df_TCZ_list_china)\n",
    " .groupby('SPZ')[['share_output_agg_o', 'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']]\n",
    " .mean().rename(index={'0': 'No SPZ', '1': 'SPZ'})\n",
    "),\n",
    "           (df_final_SOE_table2\n",
    " .assign(hinterland = lambda x: \n",
    "         np.where(\n",
    "             x['Lower_location'].isin(['Coastal']),\n",
    "             \"No\", \"Yes\")\n",
    "        )\n",
    " .groupby('hinterland')[['share_output_agg_o', 'share_fa_net_agg_o',\n",
    "       'share_employement_agg_o']]\n",
    " .mean().rename(index={'No': 'No hinterland',\n",
    "                       'Yes': 'hinterland'})\n",
    ")\n",
    "          ], axis = 0).rename(columns = {\n",
    "    'share_output_agg_o':'Output share SOE_i',\n",
    "    'share_fa_net_agg_o':'Capital share SOE_i',\n",
    "    'share_employement_agg_o':'Employment share SOE_i'\n",
    "}) .style.format('{:,.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2 bis\n",
    "\n",
    "Ouput: \n",
    "\n",
    "https://drive.google.com/open?id=1HlzY8F6gjfT03WecoIxBTAovvh4OFnBI\n",
    "\n",
    "- Overleaf\n",
    "    - Temp_tables/Tables_paper/02_paper_version_2/14_table_stat\n",
    "- Google Drive\n",
    "    - [14_table_stat](https://drive.google.com/open?id=1HlzY8F6gjfT03WecoIxBTAovvh4OFnBI)\n",
    "![](https://drive.google.com/uc?export=view&id=1HlzY8F6gjfT03WecoIxBTAovvh4OFnBI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = (df_final_SOE_table2[['target_c']]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .set_index('index')\n",
    "      .T\n",
    "      .rename(index={0: 'Full sample'}))\n",
    "t2 = df_final_SOE_table2.groupby('Lower_location')[['target_c']].mean()\n",
    "t3 = df_final_SOE_table2.groupby('Larger_location')[['target_c']].mean()\n",
    "t4 = df_final_SOE_table2.groupby('TCZ_c')[['target_c']\n",
    "                                         ].mean().rename(index={'No_TCZ':\n",
    "                                                                'No TCZ'})\n",
    "t5 = (df_final_SOE_table2\n",
    " .merge(df_herfhindal_final)\n",
    " .groupby('concentrated_city')[['target_c']]\n",
    " .mean()\n",
    ")\n",
    "t6 = df_final_SOE_table2.groupby('Coastal')[['target_c']\n",
    "                                         ].mean().rename(index={False:\n",
    "                                                                'No Coastal',\n",
    "                                                               True: 'Coastal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = (df_final_SOE_table2.groupby(['soe_city'])[['target_c']]\n",
    " .mean()\n",
    "      .T\n",
    " .rename(index={'target_c': 'Full sample'})\n",
    ")\n",
    "t8 = (df_final_SOE_table2.groupby(['soe_city','Lower_location'])[['target_c']]\n",
    " .mean()\n",
    " .unstack(0)\n",
    " .droplevel(0, axis =1)\n",
    ")\n",
    "\n",
    "t9 = (df_final_SOE_table2.groupby(['soe_city','Larger_location'])[['target_c']]\n",
    " .mean()\n",
    " .unstack(0)\n",
    " .droplevel(0, axis =1)\n",
    ")\n",
    "\n",
    "t10 = (df_final_SOE_table2.groupby(['soe_city','TCZ_c'])[['target_c']]\n",
    " .mean()\n",
    " .unstack(0)\n",
    " .droplevel(0, axis =1)\n",
    "      .rename(index={'No_TCZ':'No TCZ'})\n",
    ")\n",
    "t11 = (df_final_SOE_table2\n",
    " .merge(df_herfhindal_final)\n",
    " .groupby(['soe_city','concentrated_city'])[['target_c']]\n",
    " .mean().unstack(0).droplevel(0, axis =1)\n",
    ")\n",
    "t12 = (df_final_SOE_table2\n",
    "       .groupby(['soe_city','Coastal'])[['target_c']]\n",
    "       .mean()\n",
    "       .rename(index={False:'No Coastal',\n",
    "                      True: 'Coastal'})\n",
    "       .unstack(0)\n",
    "       .droplevel(0, axis =1)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (pd.concat([t7, t8, t9, t10, t11, t12],axis = 0)\n",
    " .reset_index()\n",
    ")['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Summary statistics of Target by city characteristics\"\n",
    "header = [\"All Cities\",\"No SOE dominated\", \"SOE dominated\"]\n",
    "\n",
    "(pd.concat([t1, t2, t3, t4, t5, t6],axis = 0)\n",
    " .rename(columns={'target_c': 'All cities'})\n",
    " .reset_index()\n",
    ").merge(\n",
    "    (pd.concat([t7, t8, t9, t10, t11, t12],axis = 0)\n",
    " .reset_index())\n",
    "    ,on = ['index']).drop_duplicates(\n",
    "    subset = \n",
    "    ['index']).set_index('index').reindex(index = \n",
    "                                          index).to_latex(\n",
    "    'table_1.tex',\n",
    "    caption = title,\n",
    "    index=True,\n",
    "    label = \"table_1\",\n",
    "    header = header,\n",
    "    float_format=\"{:,.2%}\".format)\n",
    "\n",
    "table_nte = \"\"\"\n",
    "Sources: Author's own computation \\n\n",
    "The list of TCZ is provided by the State Council, 1998. \\n\n",
    "$a$ (No) Dominated SOEs cities refer to cities where the \n",
    "(output, capital, employment) share of SOEs is (below) above a critical threshold,\n",
    "for instance the 6th decile\n",
    "      \n",
    "\"\"\"\n",
    "lb.beautify_table(table_nte = table_nte,\n",
    "                  name = 'table_1',\n",
    "                  jupyter_preview  = jupyter_preview,\n",
    "                  resolution = 200)\n",
    "\n",
    "if jupyter_preview == False:\n",
    "    source_to_move = ['table_1.tex']\n",
    "    dest = ['Overleaf_statistic/15_table_stat.tex'\n",
    "           ]\n",
    "    for i, v in enumerate(source_to_move):\n",
    "        shutil.move(\n",
    "            v,\n",
    "            dest[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 3\n",
    "\n",
    "Ouput: \n",
    "\n",
    "- Overleaf\n",
    "    - Temp_tables/Tables_paper/02_paper_version_2/13_table_stat\n",
    "- Google Drive\n",
    "    - [13_table_stat](https://drive.google.com/open?id=1ITXwbLX3XpgnZWGOgXPhnQj17680Cgey)\n",
    "![](https://drive.google.com/uc?export=view&id=1ITXwbLX3XpgnZWGOgXPhnQj17680Cgey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_herfhindal_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_3 = (\n",
    "    df_final\n",
    "    .assign(geocode4_corr = lambda x: x['geocode4_corr'].astype('str'))\n",
    "    .merge(\n",
    "        (df_chinese_city_characteristics\n",
    " .assign(geocode4_corr = lambda x: x['geocode4_corr'].astype('str'))\n",
    " .merge(df_TCZ_list_china, how = 'left')\n",
    " .merge(df_final_SOE_table2[['geocode4_corr', 'soe_city']])\n",
    " .merge(df_herfhindal_final)\n",
    " .assign(\n",
    "     TCZ = lambda x: x['TCZ'].fillna(0),\n",
    "     SPZ = lambda x: x['SPZ'].fillna('0'),\n",
    "        )\n",
    ")\n",
    "    )\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panel A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_preview = False\n",
    "title = \"Summary statistics by city characteristics\"\n",
    "#header = [\"Output share SOE_i\", \"Capital share SOE_i\",\"Employment share SOE_i\", \"Target_i\"]\n",
    "\n",
    "(df_table_3\n",
    " .assign(so2_intensity = lambda x: x['tso2_cit']/ x['population'])\n",
    " .groupby('TCZ_c')[['tso2_cit','so2_intensity','gdp_cap',\n",
    "       'population']].mean().rename(index={'No_TCZ': 'No TCZ'}).T\n",
    " .rename_axis('')\n",
    " .reset_index()\n",
    " .to_latex(\n",
    "    'table_1.tex',\n",
    "    caption = title,\n",
    "    index=False,\n",
    "    label = \"table_3\",\n",
    "    #header = header,\n",
    "    float_format=\"{:,.0f}\".format)\n",
    ")\n",
    "\n",
    "table_nte = \"\"\"\n",
    "Sources: Author's own computation \\n\n",
    "The list of TCZ is provided by the State Council, 1998. \\n\n",
    "Output $\\text { Share SOE }_{i}$ refers to the ratio of output\n",
    "(respectively capital, employment) of SOEs over the total production\n",
    "(capital, employment) in city $i$\n",
    "      \n",
    "\"\"\"\n",
    "lb.beautify_table(table_nte = False,\n",
    "                  name = 'table_1',\n",
    "                  jupyter_preview  = jupyter_preview,\n",
    "                  resolution = 200)\n",
    "\n",
    "if jupyter_preview == False:\n",
    "    source_to_move = ['table_1.tex']\n",
    "    dest = ['Overleaf_statistic/13_table_stat.tex'\n",
    "           ]\n",
    "    for i, v in enumerate(source_to_move):\n",
    "        shutil.move(\n",
    "            v,\n",
    "            dest[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only in text:\n",
    "\n",
    "GDP per capita in:\n",
    "\n",
    "- SOE/No SOE cities\n",
    "- Concentrated/ No concentrated\n",
    "- SPZ\n",
    "- Coastal \n",
    "- TCZ\n",
    "\n",
    "  & No TCZ & Concentrated & No Concentrated & SOE dominated & SOE No dominated & SOE dominated & SOE No dominated & SOE dominated & SOE No dominated\\\\\n",
    "\n",
    "Count number of city above turning point RMB:\n",
    "\n",
    "- TCZ: 28795\n",
    "- No Concentrated: 45396\n",
    "- SOE No dominated Output: 30264\n",
    "- SOE No dominated Capital: 24867\n",
    "- SOE No dominated employment: 35190 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    (df_table_3\n",
    " .assign(so2_intensity = lambda x: x['tso2_cit']/ x['population'])\n",
    " .groupby('TCZ_c')[['tso2_cit','so2_intensity','gdp_cap',\n",
    "       'population']].mean().rename(index={'No_TCZ': 'No TCZ'}).T\n",
    " #.style.format('{:,.0f}')\n",
    "),\n",
    "    (df_table_3\n",
    " .assign(so2_intensity = lambda x: x['tso2_cit']/ x['population'])\n",
    " .groupby('SPZ')[['tso2_cit','so2_intensity','gdp_cap',\n",
    "       'population']].mean().rename(index={'0': 'No SPZ', '1': 'SPZ'}).T\n",
    "),\n",
    "    (df_table_3\n",
    " .assign(so2_intensity = lambda x: x['tso2_cit']/ x['population'])\n",
    " .groupby('soe_city')[['tso2_cit','so2_intensity','gdp_cap',\n",
    "       'population']].mean().T\n",
    "),\n",
    "    (df_table_3\n",
    " .assign(so2_intensity = lambda x: x['tso2_cit']/ x['population'])\n",
    " .groupby('Coastal')[['tso2_cit','so2_intensity','gdp_cap',\n",
    "       'population']].mean().rename(index={False: 'No Coastal', \n",
    "                                          True: 'Coastal'}).T\n",
    "),\n",
    "    (df_table_3\n",
    " .assign(so2_intensity = lambda x: x['tso2_cit']/ x['population'])\n",
    " .groupby('concentrated_city')[['tso2_cit','so2_intensity','gdp_cap',\n",
    "       'population']].mean().T\n",
    ")\n",
    "], axis = 1).style.format('{:,.0f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- TCZ: 28795\n",
    "- No Concentrated: 45396\n",
    "- SOE No dominated Output: 30264\n",
    "- SOE No dominated Capital: 24867\n",
    "- SOE No dominated employment: 35190 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_table_3[['geocode4_corr', 'soe_city']]\n",
    " .drop_duplicates()['soe_city']\n",
    " .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ = {\n",
    "     'TCZ': 28795,\n",
    "     'No Concentrated': 45396,\n",
    "     'SOE No dominated Output': 30264,\n",
    "     'SOE No dominated Capital': 24867,\n",
    "     'SOE No dominated employment': 35190\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dic_.items():\n",
    "    results = (df_table_3\n",
    " .assign(count = lambda x: \n",
    "         np.where(\n",
    "             x['gdp_cap'] > value,\n",
    "             \"Above\", \"Below\")\n",
    "        )\n",
    " .loc[lambda x: x['soe_city'].isin(['SOE dominated']) \n",
    "     & x['year'].isin(['2007'])]\n",
    " [['geocode4_corr', 'count']]\n",
    " .drop_duplicates()\n",
    " ['count'].value_counts()\n",
    " .reset_index()\n",
    " .assign( percentage = lambda x: np.round(x['count']/x['count'].sum(),2) * 100)\n",
    " #.style.format('{:,.0%}', subset = ['percentage'])\n",
    ").T\n",
    "    print(\"\\n\", key, \"\\n\",results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_table_3['cityen'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dic_.items():\n",
    "    results = (df_table_3\n",
    " .assign(count = lambda x: \n",
    "         np.where(\n",
    "             x['gdp_cap'] > value,\n",
    "             \"Above\", \"Below\")\n",
    "        )\n",
    " .loc[lambda x: #x['soe_city'].isin(['SOE dominated'])  & \n",
    "      x['year'].isin(['2007'])]\n",
    " [['geocode4_corr', 'count']]\n",
    " .drop_duplicates()\n",
    " ['count'].value_counts()\n",
    " .reset_index()\n",
    " .assign( percentage = lambda x: np.round(x['count']/x['count'].sum(),2) * 100).T\n",
    " #.style.format('{:,.0%}', subset = ['percentage'])\n",
    ")\n",
    "    print(key, \"\\n\",results )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO2 emission by TCZ before and after the 11th FYP, full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = (df_final\n",
    "      .assign(\n",
    "          tso2_cit = lambda x: x['tso2_cit']/10000)\n",
    "      .groupby(['TCZ_c', 'Period', 'cityen'])\n",
    "      .agg(\n",
    "          sum_tso2_c=('tso2_cit', np.sum),\n",
    "      )\n",
    "      .groupby(level=[0, 1])\n",
    "      .agg(\n",
    "          avg_tso2=('sum_tso2_c', np.mean)\n",
    "      )\n",
    "      .sort_values(by=['TCZ_c', 'Period'], ascending=True)\n",
    "      .unstack(-1)\n",
    "      .assign(difference=lambda x: np.round(x.iloc[:, 0] - x.iloc[:, 1], 0),\n",
    "              variance=lambda x: 1-(x.iloc[:, 0] / x.iloc[:, 1])\n",
    "              )\n",
    "      .round(2)\n",
    "      .iloc[:, 2:]\n",
    "      .stack()\n",
    "      .unstack(0)\n",
    "      .rename(index={'':'Full sample'})\n",
    "      .rename_axis(\"Location\")\n",
    "      )\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO2 emission by TCZ before and after the 11th FYP, by city location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = (df_final\n",
    "      .assign(tso2_cit = lambda x: x['tso2_cit']/10000)\n",
    "      .groupby(['TCZ_c', 'Period', 'Lower_location', 'cityen'])\n",
    "      .agg(\n",
    "          sum_tso2_c=('tso2_cit', np.sum),\n",
    "      )\n",
    "      .groupby(level=[0, 1, 2])\n",
    "      .agg(\n",
    "          avg_tso2=('sum_tso2_c', np.mean)\n",
    "      )\n",
    "      .sort_values(by=['TCZ_c', 'Period'], ascending=True)\n",
    "      .unstack(-2)\n",
    "      .assign(difference=lambda x:  np.round(x.iloc[:, 0] - x.iloc[:, 1], 0),\n",
    "              variance=lambda x: 1-(x.iloc[:, 0] / x.iloc[:, 1])\n",
    "              )\n",
    "      .sort_values(by='Lower_location')\n",
    "      .round(2)\n",
    "      .iloc[:, 2:]\n",
    "      .unstack(0)\n",
    "      .droplevel(level=1, axis=1)\n",
    "      .rename_axis(\"Location\")\n",
    "      )\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO2 emission by TCZ before and after the 11th FYP, by coastal area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = (df_final\n",
    "      .assign(tso2_cit = lambda x: x['tso2_cit']/10000)\n",
    "      .groupby(['TCZ_c', 'Period', 'Coastal', 'cityen'])\n",
    "      .agg(\n",
    "          sum_tso2_c=('tso2_cit', np.sum),\n",
    "      )\n",
    "      .groupby(level=[0, 1, 2])\n",
    "      .agg(\n",
    "          avg_tso2=('sum_tso2_c', np.mean)\n",
    "      )\n",
    "      .sort_values(by=['TCZ_c', 'Period'], ascending=True)\n",
    "      .unstack(-2)\n",
    "      .assign(difference=lambda x: np.round(x.iloc[:, 0] - x.iloc[:, 1], 0),\n",
    "              variance=lambda x: 1-(x.iloc[:, 0] / x.iloc[:, 1]))\n",
    "      .sort_values(by='Coastal')\n",
    "      .round(2)\n",
    "      .iloc[:, 2:]\n",
    "      .unstack(0)\n",
    "      .droplevel(level=1, axis=1)\n",
    "      .rename_axis(\"Location\")\n",
    "      .rename(index={True:'Coastal',\n",
    "                    False: 'Non Coastal'}\n",
    "             )\n",
    "      )\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.concat([t1, t2, t3])).iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (pd.concat([t1, t2, t3]).iloc[:, :2]\n",
    " .to_latex(index=True,\n",
    "              float_format='%.2f'\n",
    "             )\n",
    ")\n",
    "t = t.replace('\\_',' ')\n",
    "t = t.replace('.00','')\n",
    "t = t.replace('TCZ c','TCZ')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "# Create report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "import os, time, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "export = 'pdf' #'html'\n",
    "\n",
    "filename = '11_SBC_tables_sum_stat'\n",
    "source = filename + '.ipynb'\n",
    "source_to_move = filename +'.{}'.format(export)\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_report = \"{}/Reports\".format(parent_path)\n",
    "dest = os.path.join(path_report, filename)+'_{}_.{}'.format(\n",
    "    aggregation_param, export\n",
    ")\n",
    "\n",
    "os.system('jupyter nbconvert --no-input --to {} {}'.format(export, source))\n",
    "\n",
    "time.sleep(5)\n",
    "shutil.move(source_to_move, dest)\n",
    "for i in range(1, 19):\n",
    "    try:\n",
    "        os.remove(\"table_{}.pdf\".format(i))\n",
    "        os.remove(\"table_{}.tex\".format(i))\n",
    "        os.remove(\"table_{}.txt\".format(i))\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "sos": {
   "kernels": [
    [
     "Python 3",
     "python3",
     "python3",
     "",
     ""
    ]
   ],
   "version": "0.21.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
